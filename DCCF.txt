â€ªarXiv:2305.02759v4 [cs.IR] 25 Feb 2024â€¬
â€ªDisentangled Contrastive Collaborative Filteringâ€¬
â€ªXubin Renâ€¬
â€ªUniversity of Hong Kongâ€¬
â€ªHong Kong, Chinaâ€¬
â€ªxubinrencs@gmail.comâ€¬
â€ªLianghao Xiaâ€¬
â€ªUniversity of Hong Kongâ€¬
â€ªHong Kong, Chinaâ€¬
â€ªaka_xia@foxmail.comâ€¬
â€ªJiashu Zhaoâ€¬
â€ªWilfrid Laurier Universityâ€¬
â€ªWaterloo, Canadaâ€¬
â€ªjzhao@wlu.caâ€¬
â€ªDawei Yinâ€¬
â€ªBaidu Incâ€¬
â€ªBeijing, Chinaâ€¬
â€ªyindawei@acm.orgâ€¬
â€ªABSTRACTâ€¬
â€ªRecent studies show that graph neural networks (GNNs) are preva- lent to model high-order relationships for collaborative filtering (CF). Towards this research line, graph contrastive learning (GCL)â€¬
â€ªhas exhibited powerful performance in addressing the supervisionâ€¬
â€ªlabel shortage issue by learning augmented user and item repre-â€¬
â€ªsentations. While many of them show their effectiveness, two keyâ€¬
â€ªquestions still remain unexplored: i) Most existing GCL-based CFâ€¬
â€ªmodels are still limited by ignoring the fact that user-item interac-â€¬
â€ªtion behaviors are often driven by diverse latent intent factors (e.g.,â€¬
â€ªshopping for family party, preferred color or brand of products); ii)â€¬
â€ªTheir introduced non-adaptive augmentation techniques are vulner-â€¬
â€ªable to noisy information, which raises concerns about the modelâ€™sâ€¬
â€ªrobustness and the risk of incorporating misleading self-supervisedâ€¬
â€ªsignals. In light of these limitations, we propose a Disentangledâ€¬
â€ªContrastive Collaborative Filtering framework (DCCF) to realizeâ€¬
â€ªintent disentanglement with self-supervised augmentation in anâ€¬
â€ªadaptive fashion. With the learned disentangled representationsâ€¬
â€ªwith global context, our DCCF is able to not only distill finer-grainedâ€¬
â€ªlatent factors from the entangled self-supervision signals but alsoâ€¬
â€ªalleviate the augmentation-induced noise. Finally, the cross-viewâ€¬
â€ªcontrastive learning task is introduced to enable adaptive augmen-â€¬
â€ªtation with our parameterized interaction mask generator. Experi-â€¬
â€ªments on various public datasets demonstrate the superiority of ourâ€¬
â€ªmethod compared to existing solutions. Our model implementationâ€¬
â€ªis released at the link https://github.com/HKUDS/DCCF.â€¬
â€ªCCS CONCEPTSâ€¬
â€ªâ€¢ Information systems â†’ Recommender systems.â€¬
â€ªKEYWORDSâ€¬
â€ªCollaborative Filtering, Contrastive Learning, Disentangled Repre-â€¬
â€ªsentation, Graph Neural Networks, Recommendationâ€¬
â€ªâˆ—Chao Huang is the corresponding author.â€¬
â€ªPermission to make digital or hard copies of all or part of this work for personal orâ€¬
â€ªclassroom use is granted without fee provided that copies are not made or distributedâ€¬
â€ªfor profit or commercial advantage and that copies bear this notice and the full citationâ€¬
â€ªon the first page. Copyrights for components of this work owned by others than theâ€¬
â€ªauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orâ€¬
â€ªrepublish, to post on servers or to redistribute to lists, requires prior specific permissionâ€¬
â€ªand/or a fee. Request permissions from permissions@acm.org.â€¬
â€ªSIGIRâ€™23, July 23â€“27, 2023, Taipei, Taiwanâ€¬
â€ªÂ© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.â€¬
â€ªACM ISBN 978-1-4503-9408-6/23/07...$15.00â€¬
â€ªhttps://doi.org/10.1145/3539618.3591665â€¬
â€ªChao Huangâˆ—â€¬
â€ªUniversity of Hong Kongâ€¬
â€ªHong Kong, Chinaâ€¬
â€ªchaohuang75@gmail.comâ€¬
â€ªACM Reference Format:â€¬
â€ªXubin Ren, Lianghao Xia, Jiashu Zhao, Dawei Yin, and Chao Huang. 2023.â€¬
â€ªDisentangled Contrastive Collaborative Filtering. In Proceedings of the 46thâ€¬
â€ªInternational ACM SIGIR Conference on Research and Development in Infor-â€¬
â€ªmation Retrieval (SIGIRâ€™23), July 23â€“27, 2023, Taipei, Taiwan. ACM, Taipei,â€¬
â€ªTaiwan, 10 pages. https://doi.org/10.1145/3539618.3591665â€¬
â€ª1 INTRODUCTIONâ€¬
â€ªRecommender systems have become fundamental services for sug-â€¬
â€ªgesting personalized items to users by learning their preferenceâ€¬
â€ªfrom historical interactions [3, 40]. Graph neural networks haveâ€¬
â€ªrecently achieved remarkable success in collaborative filtering (CF)â€¬
â€ªmodeling user-item interaction with high-order connectivity, suchâ€¬
â€ªas NGCF [32],MCCF [35], LightGCN [13], and GCCF [7]. Thoseâ€¬
â€ªGNN-based CF models encode user-item bipartite graph structuresâ€¬
â€ªinto representations via iterative message passing for collaborativeâ€¬
â€ªinformation aggregation [37]. By capturing the high-order userâ€¬
â€ª(item) similarity in latent embedding space, graph neural CF meth-â€¬
â€ªods have provided state-of-the-art recommendation performance.â€¬
â€ªHowever, user-item interactions, which serve as important labelsâ€¬
â€ªfor supervised recommendation models, are often highly sparse inâ€¬
â€ªreal-world recommender systems [41, 49, 50]. To address the issueâ€¬
â€ªof supervision shortage in recommendations, recent works [39, 42]â€¬
â€ªattempt to marry the power of contrastive learning with GNNs toâ€¬
â€ªexplore the unlabeled information and offer self-supervision signals.â€¬
â€ªThese graph contrastive learning (GCL) methods propose to learnâ€¬
â€ªinvariant user (item) representations by maximizing agreementâ€¬
â€ªbetween established contrastive augmentation views. In general, byâ€¬
â€ªfollowing the mutual information maximization principle [22, 28],â€¬
â€ªthe agreements of pre-defined positive pairs are achieved, and em-â€¬
â€ªbeddings of negative pairs are pushed apart. Two key researchâ€¬
â€ªlines of augmentation schemes have recently emerged in GCL-â€¬
â€ªbased collaborative filtering. To be specific, SGL [39] generates con-â€¬
â€ªtrastive views with stochastic augmentors, e.g., random node/edgeâ€¬
â€ªdropout. To supplement the direct graph connections, HCCF [42]â€¬
â€ªand MHCN [46] propose to purse the consistency between node-â€¬
â€ªlevel representations and graph-level semantic embeddings.â€¬
â€ªAlthough promising results have been achieved, we argue thatâ€¬
â€ªtwo key limitations exist in current GCL recommender systems.â€¬
â€ªFirst, most previous studies have ignored the fact that the latentâ€¬
â€ªfactors behind user-item interactions are highly entangled due toâ€¬
â€ªpreference diversity, resulting in suboptimal augmentation-inducedâ€¬
â€ªuser representations. In real-life applications, the formation of user-â€¬
â€ªitem interactions is driven by many intent factors [34, 36], such asâ€¬
â€ªSIGIRâ€™23, July 23â€“27, 2023, Taipei, Taiwan purchasing products for a family party or being attracted to cer-â€¬
â€ªtain clothing characteristics. However, the learned user preferencesâ€¬
â€ªwith the encoded invariant representations in current GCL-basedâ€¬
â€ªrecommendation approaches are entangled, making it difficult toâ€¬
â€ªcapture the finer-grained interaction patterns between users andâ€¬
â€ªitems. This hinders the recommenderâ€™s ability to capture genuineâ€¬
â€ªuser preferences and provide accurate intent-aware self-supervision.â€¬
â€ªTherefore, there is an urgent need for a new method that can gener-â€¬
â€ªate disentangled contrastive signals for informative augmentation.â€¬
â€ªSecond, many existing GCL-based methods still struggle to pro-â€¬
â€ªvide accurate self-supervised learning (SSL) signals against dataâ€¬
â€ªnoise, which makes it difficult to adapt contrastive learning to user-â€¬
â€ªitem interaction graphs with diverse structures. Specifically, theâ€¬
â€ªintroduced stochastic augmentation strategy [39] may not preserveâ€¬
â€ªthe original semantic relationships well, as they use random dropoutâ€¬
â€ªoperators. For example, For instance, dropping hub nodes can dam-â€¬
â€ªage important inter-community connection structures, resulting inâ€¬
â€ªan augmented user-item relation graph that may not be positivelyâ€¬
â€ªrelated to the original interaction structures. Additionally, Addi-â€¬
â€ªtionally, although some methods incorporate graph-level semanticsâ€¬
â€ªinto auxiliary self-supervised signals [42, 46] via self-discriminationâ€¬
â€ªover all nodes, their model performance is vulnerable to user in-â€¬
â€ªteraction data noise, such as misclicks or popularity bias. Under aâ€¬
â€ªcontrastive augmentation framework, if the importance of node- orâ€¬
â€ªedge-wise SSL signals is not differentiated, methods can be easilyâ€¬
â€ªbiased by supplementing the main recommendation task with self-â€¬
â€ªsupervised signals derived from noisy nodes, e.g., users with manyâ€¬
â€ªmisclick behaviors or high conformity to popularity bias [30].â€¬
â€ªIn this paper, we propose a new disentangled contrastive learning-â€¬
â€ªbased collaborative filtering model, called DCCF, to address theâ€¬
â€ªlimitations of existing methods. Specifically, Our model encodesâ€¬
â€ªmulti-intent representations by considering the global dependen-â€¬
â€ªcies between users and items. We achieve this by designing intent-â€¬
â€ªaware information passing and aggregation between patch-levelâ€¬
â€ªnodes and global-level intent prototypes. We aim to identify im-â€¬
â€ªportant graph structural information that captures accurate andâ€¬
â€ªhelpful environment-invariant patterns with intent disentangle-â€¬
â€ªment. In this way, we can prevent the distillation of self-supervisedâ€¬
â€ªinformation with severe noisy signals. To achieve our goal, weâ€¬
â€ªcreate parameterized edge mask generators that capture implicitâ€¬
â€ªrelationships among users and items, and we inject intent-awareâ€¬
â€ªglobal dependencies. As a result, the graph structure masker canâ€¬
â€ªnaturally capture the importance of each interaction for contrastiveâ€¬
â€ªaugmentation, which is adaptive to the user-item relations.â€¬
â€ªTo sum up, the main contributions of this work are as follows:â€¬
â€ªâ€¢In this work, we study the generalization problem of GCL-basedâ€¬
â€ªrecommender systems in a more challenging yet practical sce-â€¬
â€ªnario: adapting graph contrastive learning to intent disentangle-â€¬
â€ªment with self-supervision noise for collaborative filtering.â€¬
â€ªâ€¢We develop a new recommendation model called DCCF, withâ€¬
â€ªparameterized mask generators that are adaptive to build over theâ€¬
â€ªglobal context-enhanced disentangled GNN architecture. Thisâ€¬
â€ªenhances recommender robustness and generalization ability.â€¬
â€ªâ€¢Extensive experimental results demonstrate that our new methodâ€¬
â€ªachieves superior recommendation performance compared toâ€¬
â€ªmore than 10 existing solutions. Furthermore, the effectivenessâ€¬
â€ªXubin Ren, Lianghao Xia, Jiashu Zhao, Dawei Yin, & Chao Huangâ€¬
â€ªof our disentangled adaptive augmentation is justified by studiesâ€¬
â€ªof model ablation, robustness, and interpretability.â€¬
â€ª2 RELATED WORKâ€¬
â€ªGNNs-based Recommender Systems. Graph neural networksâ€¬
â€ª(GNNs) have demonstrated strong performance in representationâ€¬
â€ªlearning of user preference for recommendation. These GNN-basedâ€¬
â€ªrecommenders perform recursive message passing over graph struc-â€¬
â€ªtures to model high-order collaborative relations [8, 40, 44]. To-â€¬
â€ªwards this line, Many efforts have been made to build recommenderâ€¬
â€ªsystems based on various graph neural techniques. For instance,â€¬
â€ªgraph convolutional networks have been widely adopted as en-â€¬
â€ªcoders to model the user-item interaction graph, such as LightGCN,â€¬
â€ªLR-GCCF [7], and HGCF [25]. Additionally, graph-enhanced atten-â€¬
â€ªtion mechanisms explicitly distinguish influence for embeddingâ€¬
â€ªpropagation among neighboring nodes, and serve as importantâ€¬
â€ªcomponents in various recommenders, including social relationâ€¬
â€ªlearning DGRec [24], multi-behavior recommendation [43], knowl-â€¬
â€ªedge graph-based recommenders KGAT [31], JNSKR [4].â€¬
â€ªRecommendation with Disentangled Representations. Learn-â€¬
â€ªing disentangled representations of user latent intents from im-â€¬
â€ªplicit feedback has been a popular topic in recent years. Variousâ€¬
â€ªapproaches have been proposed, such as using variational auto-â€¬
â€ªencoders to encode high-level user intentions for improving recom-â€¬
â€ªmendation [20]. DGCF [34] builds upon this idea of intent disentan-â€¬
â€ªglement, and performs disentangled representation learning overâ€¬
â€ªgraph neural network with embedding splitting. To incorporateâ€¬
â€ªside information from user or item domain into recommendation,â€¬
â€ªDisenHAN [36] attempts to learn disentangled user/item represen-â€¬
â€ªtations with heterogeneous graph attention network. KGIN [33] isâ€¬
â€ªa method that aims to encode latent user intents using item knowl-â€¬
â€ªedge graph to improve recommendation performance. DCF [10]â€¬
â€ªdecomposes users and items into factor-level representations andâ€¬
â€ªusing a factor-level attention mechanism to capture the underly-â€¬
â€ªing intents. In CDR [6], a dynamic routing mechanism is designedâ€¬
â€ªto characterize correlations among user intentions for embeddingâ€¬
â€ªdenoising. However, most existing disentangled recommender sys-â€¬
â€ªtems are built in a fully supervised manner, which can be limitedâ€¬
â€ªby the sparsity of user-item interactions in real-world scenarios.â€¬
â€ªTo address this challenge, we propose a new model that leveragesâ€¬
â€ªself-supervised learning for intent-aware augmentation.â€¬
â€ªContrastive Learning in Recommendation. Recently, contrastiveâ€¬
â€ªlearning (CL) has gained considerable attention in various rec-â€¬
â€ªommendation scenarios, such as sequential recommendation [9],â€¬
â€ªknowledge graph-enhanced recommendation [51], multi-interestâ€¬
â€ªrecommendation [47] and multi-behavior recommendation [38].â€¬
â€ªThe most relevant research line in recommendation systems is toâ€¬
â€ªenhance graph neural network (GNN)-based collaborative filteringâ€¬
â€ªwith contrastive learning. To this end, several recently proposedâ€¬
â€ªmodels, such as SGL [39], NCL [17], and HCCF [42], have achievedâ€¬
â€ªstate-of-the-art performance by leveraging contrastive augmen-â€¬
â€ªtation. For example, SGL [39] uses random dropout operators toâ€¬
â€ªcorrupt interaction graph structures for augmentation. In NCL [17],â€¬
â€ªrepresentation alignment is performed between individual usersâ€¬
â€ªand semantic-centric nodes. While these models have been effec-â€¬
â€ªtive in improving recommendation accuracy, they may fall shortâ€¬
â€ªin encoding latent factors behind user-item interactions, whichâ€¬
â€ªDisentangled Contrastive Collaborative Filtering can result in suboptimal representations with coarse-grained userâ€¬
â€ªpreference modeling for recommendation.â€¬
â€ª3 METHODOLOGYâ€¬
â€ª3.1 Disentangled Intent Representationâ€¬
â€ª3.1.1 Modeling Latent Intent Factors. In our recommendationâ€¬
â€ªscenario, we represent the interaction matrix between the user setâ€¬
â€ªU= ğ‘¢1,...,ğ‘¢ğ‘–,...,ğ‘¢ğ¼ (with size ğ¼) and item set I= ğ‘£1,...,ğ‘£ğ‘—,...,ğ‘£ğ½â€¬
â€ª(with size ğ½) as AâˆˆRğ¼Ã—ğ½. The entry Ağ‘–,ğ‘— âˆˆAis set to 1 if user ğ‘¢ğ‘–â€¬
â€ªhas adopted item ğ‘£ğ‘— before, and Ağ‘–,ğ‘—= 0 otherwise. Our model aimsâ€¬
â€ªto predict the likelihood that a candidate user will adopt an itemâ€¬
â€ªgiven their observed interactions. From a probabilistic perspective,â€¬
â€ªour predictive model aims to estimate the conditional probabilityâ€¬
â€ªğ‘ƒ(ğ‘¦|ğ‘¢ğ‘–,ğ‘£ğ‘—)for the interaction between user ğ‘¢ğ‘– and item ğ‘£ğ‘—, whereâ€¬
â€ªğ‘¦is the learned preference score.â€¬
â€ªWhen interacting with items, users often have diverse intents,â€¬
â€ªsuch as preferences for specific brands or interests in the genresâ€¬
â€ªand actors of movies [21, 48]. To capture these diverse intents, weâ€¬
â€ªassume ğ¾ different intents ğ‘ğ‘¢ and ğ‘ğ‘£ from the user and item sides,â€¬
â€ªrespectively. The intent on the item side can also be understood asâ€¬
â€ªthe context of the item, for example, a user who intends to shopâ€¬
â€ªfor Valentineâ€™s Day may have a preference for items that have aâ€¬
â€ªâ€œromanticâ€ context. Our predictive objective of user-item preferenceâ€¬
â€ªcan be presented as follows:â€¬
â€ªâˆ«ğ‘ğ‘¢ âˆ«ğ‘ğ‘£â€¬
â€ªğ‘ƒ(ğ‘¦,ğ‘ğ‘¢,ğ‘ğ‘£|ğ‘¢,ğ‘£)ğ‘‘ğ‘ğ‘£ğ‘‘ğ‘ğ‘¢ =â€¬
â€ªğ¾â€¬
â€ªâˆ‘ï¸â€¬
â€ªğ‘˜â€¬
â€ªğ‘ƒ(ğ‘¦,ğ‘ğ‘˜â€¬
â€ªğ‘¢,ğ‘ğ‘˜â€¬
â€ªğ‘£|ğ‘¢,ğ‘£) (1)â€¬
â€ªThe user-item interaction probability ğ‘¦ is determined by theâ€¬
â€ªlatent intents ğ‘ğ‘¢ and ğ‘ğ‘£ and can be derived using the formulas:â€¬
â€ªğ¾â€¬
â€ªâˆ‘ï¸â€¬
â€ªğ‘˜â€¬
â€ªğ¾â€¬
â€ªğ‘ƒ(ğ‘¦,ğ‘ğ‘˜â€¬
â€ªğ‘¢,ğ‘ğ‘˜â€¬
â€ªğ‘£|ğ‘¢,ğ‘£)=â€¬
â€ªâˆ‘ï¸â€¬
â€ªğ‘ƒ(ğ‘¦|ğ‘ğ‘˜â€¬
â€ªğ‘¢,ğ‘ğ‘˜â€¬
â€ªğ‘£)ğ‘ƒ(ğ‘ğ‘˜â€¬
â€ªğ‘¢|ğ‘¢)ğ‘ƒ(ğ‘ğ‘˜â€¬
â€ªğ‘£|ğ‘£) (2)â€¬
â€ªğ‘˜â€¬
â€ª= Eğ‘ƒ(ğ‘ğ‘¢ |ğ‘¢)ğ‘ƒ(ğ‘ğ‘£ |ğ‘£)[ğ‘ƒ(ğ‘¦|ğ‘ğ‘¢,ğ‘ğ‘£)]. (3)â€¬
â€ªHere, we use ğ‘“(Â·)to denote the forecasting function over the en-â€¬
â€ªcoded intents. Following the statistical theory in [29, 30], we makeâ€¬
â€ªthe following approximation to derive our prediction objective:â€¬
â€ªEğ‘ƒ(ğ‘ğ‘¢ |ğ‘¢)ğ‘ƒ(ğ‘ğ‘£ |ğ‘£)[ğ‘“(ğ‘ğ‘¢,ğ‘ğ‘£)]â‰ˆğ‘“(Eğ‘ƒ(ğ‘ğ‘¢ |ğ‘¢)[ğ‘ğ‘¢],Eğ‘ƒ(ğ‘ğ‘£ |ğ‘£)[ğ‘ğ‘£]). (4)â€¬
â€ªWith the above inference, the approximation error, known as Jensenâ€¬
â€ªgap [1], can be well bounded in our forecasting function ğ‘“(Â·)[12].â€¬
â€ª3.1.2 Multi-Intent Representation with Global Context. Whileâ€¬
â€ªintent diversity has been encoded in existing recommender systemsâ€¬
â€ªthrough disentangled representations, global-level intent-aware col-â€¬
â€ªlaborative relations have been largely overlooked. Global-level userâ€¬
â€ª(item) dependency modeling can enhance the robustness of GNN-â€¬
â€ªbased message passing models against sparsity and over-smoothingâ€¬
â€ªissue, via propagating information without the limitation of directâ€¬
â€ªlocal connections [42]. Towards this end, we propose to disentangleâ€¬
â€ªcollaborative relations among users and items with both local- andâ€¬
â€ªglobal-level embedding for information propagation.â€¬
â€ªGraph-based Message Passing. Owing to the strength of graphâ€¬
â€ªneural networks, GNNs has become the prevalent learning para-â€¬
â€ªdigm to capture collaborative filtering signals in state-of-the-art rec-â€¬
â€ªommender systems. Examples include LightGCN [13], LR-GCCF [7],â€¬
â€ªand HGCF [25]. The insights offered by these studies have inspiredâ€¬
â€ªSIGIRâ€™23, July 23â€“27, 2023, Taipei, Taiwanâ€¬
â€ªus to build our DCCF model using a graph-based message passingâ€¬
â€ªframework for user representations. In general, our message propa-â€¬
â€ªgation layer is formally presented with the user/item embeddingâ€¬
â€ªmatrix E(ğ‘¢) âˆˆRğ¼Ã—ğ‘‘ and E(ğ‘£) âˆˆRğ½Ã—ğ‘‘ as follows:â€¬
â€ªZ(ğ‘¢)=Â¯â€¬
â€ªAÂ·E(ğ‘£)â€¬
â€ª, Z(ğ‘£)=Â¯â€¬
â€ªAğ‘‡â€¬
â€ªÂ·E(ğ‘¢)â€¬
â€ª, (5)â€¬
â€ªThe aggregated representations from neighboring nodes to theâ€¬
â€ªtarget ones are denoted by Z(ğ‘¢) âˆˆRğ¼Ã—ğ‘‘ and Z(ğ‘£) âˆˆRğ½Ã—ğ‘‘. Here,â€¬
â€ªÂ¯â€¬
â€ªAâˆˆRğ¼Ã—ğ½ denotes the normalized adjacent matrix which is derivedâ€¬
â€ªfrom the user-item interaction matrix AasÂ¯â€¬
â€ªA= Dâˆ’1/2â€¬
â€ª(ğ‘¢) Â·AÂ·Dâˆ’1/2â€¬
â€ª(ğ‘£).â€¬
â€ªwhere D(ğ‘¢) âˆˆRğ¼Ã—ğ¼ and D(ğ‘£) âˆˆRğ½Ã—ğ½ are diagonal degree matrices.â€¬
â€ªTo exploit high-order collaborative filtering signals, we performâ€¬
â€ªGNN-based embedding propagation across different graph layers,â€¬
â€ªsuch as from the (ğ‘™âˆ’1)-th to the (ğ‘™)-th layer, as follows:â€¬
â€ªE(ğ‘¢)â€¬
â€ª= E(ğ‘¢)â€¬
â€ªğ‘™â€¬
â€ªğ‘™âˆ’1 +Z(ğ‘¢)â€¬
â€ªğ‘™âˆ’1, E(ğ‘£)â€¬
â€ª= E(ğ‘£)â€¬
â€ªğ‘™â€¬
â€ªğ‘™âˆ’1 +Z(ğ‘£)â€¬
â€ªğ‘™âˆ’1, (6)â€¬
â€ªTo suppress the over-smoothing effect, residual connections areâ€¬
â€ªapplied to the aggregation phase [7, 42].â€¬
â€ªIntent-aware Information Aggregation. We will describe howâ€¬
â€ªto incorporate intent-aware global user (item) dependencies intoâ€¬
â€ªour GNN-based collaborative filtering framework. In our multi-â€¬
â€ªintent encoder, disentangled user-item preferences are preservedâ€¬
â€ªin Eğ‘ƒ(ğ‘ğ‘¢ |ğ‘¢)[ğ‘ğ‘¢]and Eğ‘ƒ(ğ‘ğ‘£ |ğ‘£)[ğ‘ğ‘£]. In our DCCF, we define ğ¾ globalâ€¬
â€ªintent prototypes {cğ‘˜â€¬
â€ªğ‘¢ âˆˆRğ‘‘}ğ¾â€¬
â€ªğ‘˜=1 and {cğ‘˜â€¬
â€ªğ‘£ âˆˆRğ‘‘}ğ¾â€¬
â€ªğ‘˜=1 for user andâ€¬
â€ªitem, respectively. With these learnable intent embeddings, weâ€¬
â€ªgenerate user and item representations by aggregating informationâ€¬
â€ªacross different ğ¾ intent prototypes with the global context at theâ€¬
â€ªğ‘™-th graph embedding layer, using the following design:â€¬
â€ªğ¾â€¬
â€ªr(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™= Eğ‘ƒ(cğ‘¢ |e(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™ )[cğ‘¢]=â€¬
â€ªâˆ‘ï¸â€¬
â€ªcğ‘˜â€¬
â€ªğ‘¢ğ‘ƒ(cğ‘˜â€¬
â€ªğ‘¢|e(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™ ), (7)â€¬
â€ªğ‘˜â€¬
â€ªğ¾â€¬
â€ªr(ğ‘£)â€¬
â€ªğ‘—,ğ‘™= Eğ‘ƒ(cğ‘£ |e(ğ‘£)â€¬
â€ªğ‘—,ğ‘™ )[cğ‘£]=â€¬
â€ªâˆ‘ï¸â€¬
â€ªcğ‘˜â€¬
â€ªğ‘£ğ‘ƒ(cğ‘˜â€¬
â€ªğ‘£|e(ğ‘£)â€¬
â€ªğ‘—,ğ‘™ ), (8)â€¬
â€ªğ‘˜â€¬
â€ªThe ğ‘™-th layer-specific user and item embeddings are denoted byâ€¬
â€ªe(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™ âˆˆE(ğ‘¢)â€¬
â€ªğ‘™ and e(ğ‘£)â€¬
â€ªğ‘—,ğ‘™ âˆˆE(ğ‘£)â€¬
â€ªğ‘™ , respectively. The relevance score be-â€¬
â€ªtween user ğ‘¢ğ‘– and each intent prototype cğ‘¢ is defined as ğ‘ƒ(cğ‘˜â€¬
â€ªğ‘¢|e(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™ ),â€¬
â€ªwhich can be derived as follows:â€¬
â€ªğœ‚(e(ğ‘¢)âŠ¤â€¬
â€ªğ‘–,ğ‘™âˆ’1 cğ‘˜â€¬
â€ªğ‘ƒ(cğ‘˜â€¬
â€ªğ‘¢|e(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™ )=â€¬
â€ªğ‘¢)â€¬
â€ªğœ‚(e(ğ‘£)âŠ¤â€¬
â€ªğ‘—,ğ‘™âˆ’1cğ‘˜â€¬
â€ª,ğ‘ƒ(cğ‘˜â€¬
â€ªğ‘£|e(ğ‘£)â€¬
â€ªğ¾â€¬
â€ªğ‘˜â€²ğœ‚(e(ğ‘¢)âŠ¤â€¬
â€ªğ‘—,ğ‘™ )=â€¬
â€ªğ‘–,ğ‘™âˆ’1 cğ‘˜â€²â€¬
â€ªğ‘¢ )â€¬
â€ªğ‘£)â€¬
â€ªğ¾â€¬
â€ªğ‘˜â€²ğœ‚(e(ğ‘£)âŠ¤â€¬
â€ªğ‘—,ğ‘™âˆ’1cğ‘˜â€²â€¬
â€ªğ‘£ )â€¬
â€ªHere, ğœ‚(Â·)= exp(Â·). After generating the propagated message, weâ€¬
â€ªrefine it by integrating the local collaborative filtering signals withâ€¬
â€ªthe global disentangled collaborative relations, as follows:â€¬
â€ªE(ğ‘¢)â€¬
â€ª= E(ğ‘¢)â€¬
â€ªğ‘™â€¬
â€ªğ‘™âˆ’1 +Z(ğ‘¢)â€¬
â€ªğ‘™âˆ’1 +R(ğ‘¢)â€¬
â€ªğ‘™âˆ’1, E(ğ‘£)â€¬
â€ª= E(ğ‘£)â€¬
â€ªğ‘™â€¬
â€ªğ‘™âˆ’1 +Z(ğ‘£)â€¬
â€ªğ‘™âˆ’1 +R(ğ‘£)â€¬
â€ªğ‘™âˆ’1. (9)â€¬
â€ªIn this equation, R(ğ‘¢)â€¬
â€ªğ‘™âˆ’1 âˆˆRğ¼Ã—ğ‘‘ and R(ğ‘£)â€¬
â€ªğ‘™âˆ’1 âˆˆRğ½Ã—ğ‘‘ represent theâ€¬
â€ªstacked intent-aware user embeddings (r(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™âˆ’1) and item embeddingsâ€¬
â€ª(r(ğ‘£)â€¬
â€ªğ‘—,ğ‘™âˆ’1), respectively. Incorporating intent disentanglement into theâ€¬
â€ªgraph neural architecture enables our learned representations toâ€¬
â€ªSIGIRâ€™23, July 23â€“27, 2023, Taipei, Taiwan Xubin Ren, Lianghao Xia, Jiashu Zhao, Dawei Yin, & Chao Huangâ€¬
â€ªLocal-basedâ€¬
â€ªLatent Intent Spaceâ€¬
â€ªMessageâ€¬
â€ªPassingâ€¬
â€ªâˆ’1/2â€¬
â€ªâˆ’1/2 ğƒğƒ(ğ‘£ğ‘£)â€¬
â€ªğƒğƒ(ğ‘¢ğ‘¢)â€¬
â€ªğ“ğ“â€¬
â€ªğğâ€¬
â€ªğ³ğ³â€¬
â€ªNextâ€¬
â€ªGNN Layerâ€¬
â€ªâ„’ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘â€¬
â€ªğ³ğ³â€¬
â€ªğœğœâ€¬
â€ªğ¡ğ¡ğ›½ğ›½â€¬
â€ª+â€¬
â€ªLast Layerâ€¬
â€ªğœğœâ€¬
â€ªGlobal-basedâ€¬
â€ªğğ ğ³ğ³ ğ«ğ« ğ¡ğ¡ğ›½ğ›½â€¬
â€ªğ¡ğ¡ğ›¾ğ›¾â€¬
â€ªğ”¼ğ”¼ ğ‘ƒğ‘ƒ ğ’„ğ’„ ğ’†ğ’† ğ’„ğ’„â€¬
â€ªğ«ğ«â€¬
â€ªğ“ğ“=â€¬
â€ªğ«ğ«â€¬
â€ªğœğœâ€¬
â€ªğ¡ğ¡ğ›¾ğ›¾â€¬
â€ªğ‘ƒğ‘ƒ ğœğœ ğğ)â€¬
â€ªSelf-Supervised Signal â„’ğ‘ ğ‘ â€¬
â€ªUser Itemâ€¬
â€ª(a) Interaction Graph (b) Graph-local Learning (c) Intent-aware Encoding (d) Adaptive Augmentation (e) Model Aggregationâ€¬
â€ªFigure 1: The overall framework of our proposed DCCF model involves adaptive augmentation through the integration of globalâ€¬
â€ªintent disentanglement and interaction pattern encoding, resulting in disentangled environment-invariant representations.â€¬
â€ªeffectively disentangle the latent factors driving complex user-itemâ€¬
â€ªinteraction behaviors.â€¬
â€ª3.2 Disentangled Contrastive Learningâ€¬
â€ªTaking inspiration from recent developments in contrastive learn-â€¬
â€ªing, we explore the potential of contrastive augmentation withâ€¬
â€ªintent disentanglement to address the data sparsity issue in recom-â€¬
â€ªmender systems. Although self-supervision signals can be gener-â€¬
â€ªated by maximizing the consistency between positive pairs amongâ€¬
â€ªcontrastive views, we argue that such augmentation is susceptibleâ€¬
â€ªto data noise, such as misclicks. Noisy contrastive regularizationâ€¬
â€ªmay mislead the self-supervised learning process. For instance,â€¬
â€ªreinforcing the model to achieve embedding agreement via nodeâ€¬
â€ªself-discrimination on noisy interaction edges may involve noisyâ€¬
â€ªself-supervised signals and lead to suboptimal representations.â€¬
â€ªTo address this challenge, we design learnable augmenters thatâ€¬
â€ªconsider both local collaborative relations and global disentangledâ€¬
â€ªuser (item) dependencies. By doing so, the learnable contrastiveâ€¬
â€ªaugmenters can adaptively learn disentangled SSL signals.â€¬
â€ª3.2.1 Disentangled Data Augmentation. To enable the aug-â€¬
â€ªmentation to be adaptive to each connection hop, we introduce aâ€¬
â€ªlearnable relation matrix Gğ‘™ âˆˆRğ¼Ã—ğ½ for each (ğ‘™)-th GNN layer toâ€¬
â€ªencode the implicit relationships between users and items. Inspiredâ€¬
â€ªby previous work on graph denoising [18, 26], we aim to generateâ€¬
â€ªa graph mask Mğ‘™ âˆˆRğ¼Ã—ğ½, which can be used to obtain the relationâ€¬
â€ªmatrix through element-wise multiplication: Gğ‘™ = Mğ‘™ âŠ™A.â€¬
â€ªLearning Graph Mask. Each entry Mğ‘™â€¬
â€ªğ‘–,ğ‘— âˆˆ[0,1]in the graph maskâ€¬
â€ªMğ‘™ reflects the degree to which the interaction between user ğ‘–andâ€¬
â€ªitem ğ‘— is masked. The closer the value is to 0, the less important theâ€¬
â€ªinteraction is, and vice versa. In our DCCF model, we derive Mğ‘™â€¬
â€ªğ‘–,ğ‘—â€¬
â€ªbased on the disentangled embeddings of user (r(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™ ) and item (r(ğ‘£)â€¬
â€ªğ‘–,ğ‘™ )â€¬
â€ªto preserve the intent-aware interaction patterns. Specifically, weâ€¬
â€ªuse cosine similarity [11, 26] between node embeddings to measureâ€¬
â€ªthe importance of interactions:â€¬
â€ªğ‘ (r(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™,r(ğ‘£)â€¬
â€ªğ‘—,ğ‘™ )=â€¬
â€ªr(ğ‘¢)â€¬
â€ªğ‘‡â€¬
â€ªr(ğ‘£)â€¬
â€ªğ‘–,ğ‘™â€¬
â€ªğ‘—,ğ‘™â€¬
â€ªâˆ¥r(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™ âˆ¥2 âˆ¥r(ğ‘£)â€¬
â€ªğ‘—,ğ‘™ âˆ¥2â€¬
â€ª. (10)â€¬
â€ªThe mask value is obtained by linearly transforming the range of theâ€¬
â€ªsimilarity to [0,1], using the formula: Mğ‘™â€¬
â€ªğ‘–,ğ‘—= (ğ‘ (r(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™,r(ğ‘£)â€¬
â€ªğ‘—,ğ‘™ )+1)/2.â€¬
â€ªLearnable Augmentation. Ağ‘–,ğ‘— is 0 when there is no interactionâ€¬
â€ªbetween user ğ‘–and item ğ‘—. Gğ‘™ is obtained by element-wise multipli-â€¬
â€ªcation of Mğ‘™ and A. only the mask values of observed interactionsâ€¬
â€ªare calculated for computational simplicity. With the learned rela-â€¬
â€ªtion matrix, we then normalize it with the degree of the node asâ€¬
â€ªfollows (layer index is omitted for simplicity):â€¬
â€ªğ½â€¬
â€ªÂ¯â€¬
â€ªGğ‘–,ğ‘—= Gğ‘–,ğ‘—/â€¬
â€ªâˆ‘ï¸â€¬
â€ªğ‘—â€²â€¬
â€ªğ¼â€¬
â€ªGğ‘–,ğ‘—,Â¯â€¬
â€ªGğ‘‡â€¬
â€ªğ‘—,ğ‘–= Gğ‘‡â€¬
â€ªğ‘—,ğ‘–/â€¬
â€ªâˆ‘ï¸â€¬
â€ªğ‘–â€²â€¬
â€ªGğ‘‡â€¬
â€ªğ‘—,ğ‘–â€². (11)â€¬
â€ªTo integrate our adaptive augmentation with the message passingâ€¬
â€ªscheme, we apply our normalized learned relation matrixÂ¯â€¬
â€ªGğ‘™ overâ€¬
â€ªthe messages of nodes for learnable propagation. With this design,â€¬
â€ªwe perturb the graph structure to generate contrastive learningâ€¬
â€ªviews with adaptive augmentation. The augmentation with adaptiveâ€¬
â€ªmasking can be formally presented as follows:â€¬
â€ªH(ğ‘¢)â€¬
â€ª=Â¯â€¬
â€ªğ‘™â€¬
â€ªGÂ·E(ğ‘£)â€¬
â€ªğ‘™, H(ğ‘£)â€¬
â€ªğ‘™â€¬
â€ª=Â¯â€¬
â€ªGğ‘‡â€¬
â€ªÂ·E(ğ‘¢)â€¬
â€ªğ‘™, (12)â€¬
â€ªTo generate multiple contrastive views, we consider both local col-â€¬
â€ªlaborative signals and global disentangled relationships. In particu-â€¬
â€ªlar, we perform augmentation using two learnable mask matricesâ€¬
â€ªover encoded local embeddings (Z(ğ‘¢)â€¬
â€ªğ‘™ and Z(ğ‘£)â€¬
â€ªğ‘™ in Eq. 5), and globalâ€¬
â€ªembeddings with intent disentanglement (R(ğ‘¢)â€¬
â€ªğ‘™ and R(ğ‘£)â€¬
â€ªğ‘™ in Eq. 7).â€¬
â€ªWe derive two mask values Mğ‘™â€¬
â€ªğ‘–,ğ‘— separately using the following for-â€¬
â€ªmulas: Mğ‘™â€¬
â€ªğ‘–,ğ‘—= (ğ‘ (r(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™,r(ğ‘£)â€¬
â€ªğ‘—,ğ‘™ )+1)/2 and Mâ€²,ğ‘™â€¬
â€ªğ‘–,ğ‘—= (ğ‘ (z(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™,z(ğ‘£)â€¬
â€ªğ‘—,ğ‘™ )+1)/2.â€¬
â€ªAfter that, our augmentation-aware message passing paradigm canâ€¬
â€ªbe described with the following embedding refinement details:â€¬
â€ªE(ğ‘¢)â€¬
â€ª= E(ğ‘¢)â€¬
â€ªğ‘™â€¬
â€ªğ‘™âˆ’1 +Z(ğ‘¢)â€¬
â€ªğ‘™âˆ’1 +R(ğ‘¢)â€¬
â€ªğ‘™âˆ’1 +Hğ›½,(ğ‘¢)â€¬
â€ªğ‘™âˆ’1 +Hğ›¾,(ğ‘¢)â€¬
â€ªğ‘™âˆ’1 (13)â€¬
â€ªHere, Hğ›½,(ğ‘¢)â€¬
â€ªğ‘™âˆ’1 and Hğ›¾,(ğ‘¢)â€¬
â€ªğ‘™âˆ’1 represent the local- and global-level aug-â€¬
â€ªmented representations, respectively. Similarly, item embeddingsâ€¬
â€ªare fused in an analogous manner.â€¬
â€ª3.2.2 Contrastive Learning. Using the above augmented repre-â€¬
â€ªsentation views, we conduct contrastive learning across differentâ€¬
â€ªview-specific embeddings of users and items. Following the ap-â€¬
â€ªproach of supervised contrastive signals in [39, 42], we generateâ€¬
â€ªeach positive pair using the embeddings of the same user (item)â€¬
â€ªfrom the original CF view and each of the augmented views. Theâ€¬
â€ªencoded representations of different nodes are treated as nega-â€¬
â€ªtive pairs. Specifically, we generate three augmented views usingâ€¬
â€ªDisentangled Contrastive Collaborative Filtering our augmenters: i) the local collaborative view with adaptive aug-â€¬
â€ªmentation (Hğ›½,(ğ‘¢)); ii) the disentangled global collaborative viewâ€¬
â€ª(R(ğ‘¢)); and iii) the adaptive augmented view (Hğ›¾,(ğ‘¢)). We generateâ€¬
â€ªcontrastive self-supervision signals using InfoNCE loss as follows:â€¬
â€ªI(m,n)=â€¬
â€ª1â€¬
â€ªğ¼â€¬
â€ªğ¼â€¬
â€ªâˆ‘ï¸â€¬
â€ªğ‘–=0â€¬
â€ªğ¿â€¬
â€ªâˆ‘ï¸â€¬
â€ªğ‘™=0â€¬
â€ªexp(ğ‘ (m(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™,n(ğ‘¢)â€¬
â€ªâˆ’logâ€¬
â€ªğ‘–,ğ‘™ )/ğœ)â€¬
â€ªğ¼â€¬
â€ªğ‘–â€²=0 exp(ğ‘ (m(ğ‘¢)â€¬
â€ªğ‘–,ğ‘™,n(ğ‘¢)â€¬
â€ªğ‘–â€²,ğ‘™ )/ğœ), (14)â€¬
â€ªHere, m denotes the original view with vanilla embeddings (z âˆˆâ€¬
â€ªZ(ğ‘¢)) encoded from GNN. n is sampled from one of three aug-â€¬
â€ªmented embeddings hğ›½ âˆˆHğ›½,(ğ‘¢)â€¬
â€ª, R(ğ‘¢), and hğ›¾ âˆˆHğ›¾,(ğ‘¢). Theâ€¬
â€ªcosine similarity function is denoted by ğ‘ (Â·). The contrastive learn-â€¬
â€ªing loss from the user side can be formalized as follows:â€¬
â€ªL(ğ‘¢)â€¬
â€ªğ‘ğ‘™â€¬
â€ª= I(z,r)+I(z,hğ›½)+I(z,hğ›¾) (15)â€¬
â€ªBy stacking ğ¿graph neural layers, the layer-specific embeddingsâ€¬
â€ªare aggregated across different layers as follows: E(ğ‘¢)= ğ¿â€¬
â€ªğ‘™=0 E(ğ‘¢)â€¬
â€ªğ‘™â€¬
â€ªand E(ğ‘£)= ğ¿â€¬
â€ªğ‘™=0 E(ğ‘£)â€¬
â€ªğ‘™ . The user-item preference score is derived as:â€¬
â€ªY= E(ğ‘¢)(E(ğ‘£))ğ‘‡â€¬
â€ª, Yğ‘–,ğ‘—= (e(ğ‘¢)â€¬
â€ªğ‘– )ğ‘‡e(ğ‘£)â€¬
â€ªğ‘—. (16)â€¬
â€ªTo optimize the classical supervised recommendation task usingâ€¬
â€ªthe estimated preference score, we use the following Bayesian Per-â€¬
â€ªsonalized Ranking (BPR) loss:â€¬
â€ª1â€¬
â€ªLğ‘ğ‘ğ‘Ÿ=âˆ’â€¬
â€ª|R| âˆ‘ï¸â€¬
â€ªğ‘™ğ‘›ğœ(Yğ‘–,ğ‘ğ‘ âˆ’Yğ‘–,ğ‘›ğ‘  ), (17)â€¬
â€ª(ğ‘–,ğ‘ğ‘  ,ğ‘›ğ‘  )âˆˆRâ€¬
â€ªwhere Ris the set of sampled interactions in each mini-batch [13].â€¬
â€ªFor each user ğ‘¢ğ‘–, we sample ğ‘† positive items (indexed by ğ‘ğ‘ ) and ğ‘†â€¬
â€ªnegative items (indexed by ğ‘›ğ‘ ) from the training data.â€¬
â€ªFinally, we integrate the self-supervised loss with our classicalâ€¬
â€ªrecommendation loss into a multi-task learning objective as follows:â€¬
â€ªL= Lğ‘ğ‘ğ‘Ÿ +ğœ†1 Â·(L(ğ‘¢)â€¬
â€ªğ‘ğ‘™ +L(ğ‘£)â€¬
â€ªğ‘ğ‘™ )+ğœ†2 Â·âˆ¥Î˜1 âˆ¥2â€¬
â€ªF +ğœ†3 Â·âˆ¥Î˜2 âˆ¥2â€¬
â€ªF (18)â€¬
â€ªwhere ğœ†1, ğœ†2 and ğœ†3 are tunable weights. Î˜1 = {E(ğ‘¢)â€¬
â€ª0 ,E(ğ‘£)â€¬
â€ª0 }andâ€¬
â€ªÎ˜2 = {{cğ‘˜â€¬
â€ªğ‘¢}ğ¾â€¬
â€ªğ‘˜=1,{cğ‘˜â€¬
â€ªğ‘£}ğ¾â€¬
â€ªğ‘˜=1}are trainable parameters in our model.â€¬
â€ª3.3 Discussions on DCCF Modelâ€¬
â€ªIn this section, we present theoretical analyses of the benefits of ourâ€¬
â€ªdisentangled contrastive learning paradigm. Initially, for a specificâ€¬
â€ªuser ğ‘¢ğ‘–, the corresponding contrastive self-supervised learning sig-â€¬
â€ªnals are incorporated with I(r(ğ‘¢)â€¬
â€ªğ‘– ,z(ğ‘¢)â€¬
â€ªğ‘– ), where r(ğ‘¢)â€¬
â€ªğ‘– is the encodedâ€¬
â€ªembedding of ğ‘¢ğ‘– from the augmentation with intent-aware userâ€¬
â€ªglobal dependency. The gradients of I(r(ğ‘¢)â€¬
â€ªğ‘– ,z(ğ‘¢)â€¬
â€ªğ‘– )with respect toâ€¬
â€ªthe disentangled representation r(ğ‘¢)â€¬
â€ªğ‘– contributed by negative sam-â€¬
â€ªples can be derived as follows:â€¬
â€ªğ‘(ğ‘–â€²)=â€¬
â€ªÃ—â€¬
â€ªr(ğ‘¢)â€¬
â€ªğ‘–â€¬
â€ªâˆ’ğ‘ (r(ğ‘¢)â€¬
â€ªğ‘– ,z(ğ‘¢)â€¬
â€ªğ‘–â€² )â€¬
â€ªâˆ¥r(ğ‘¢)â€¬
â€ªğ‘– âˆ¥2â€¬
â€ªexp(ğ‘ (r(ğ‘¢)â€¬
â€ªğ‘– ,zâ€²(ğ‘¢)â€¬
â€ªğ‘– )/ğœ)â€¬
â€ªğ‘–â€²exp(ğ‘ (r(ğ‘¢)â€¬
â€ªğ‘– ,z(ğ‘¢)â€¬
â€ªğ‘–â€² /ğœ)â€¬
â€ª(19)â€¬
â€ªz(ğ‘¢)â€¬
â€ªğ‘–â€¬
â€ªâˆ¥zâ€²(ğ‘¢)â€¬
â€ªğ‘– âˆ¥2â€¬
â€ªSIGIRâ€™23, July 23â€“27, 2023, Taipei, Taiwanâ€¬
â€ªWithout loss of generality, we omit the index of graph layers. Here,â€¬
â€ªğ‘–â€²denotes the negative sample ğ‘¢â€²â€¬
â€ªğ‘– for ğ‘¢ğ‘– (ğ‘–â€²â‰  ğ‘–& 1 â‰¤ğ‘– â‰¤ğ¼). The L2â€¬
â€ªnorm of ğ‘(ğ‘–â€²)is proportional to a special function as follows:â€¬
â€ªâˆ¥ğ‘(ğ‘–â€²)âˆ¥2 âˆâˆšï¸ƒ1âˆ’ğ‘ (r(ğ‘¢)â€¬
â€ªğ‘ (r(ğ‘¢)â€¬
â€ªğ‘– ,z(ğ‘¢)â€¬
â€ªğ‘– ,z(ğ‘¢)â€¬
â€ªğ‘–â€² )â€¬
â€ªğ‘–â€² )2 Â·exp(â€¬
â€ª) (20)â€¬
â€ªğœâ€¬
â€ªIn the above equation, ğ‘ (r(ğ‘¢)â€¬
â€ªğ‘– ,z(ğ‘¢)â€¬
â€ªğ‘–â€² )âˆˆ[âˆ’1,1]. For hard negativeâ€¬
â€ªsamples, the corresponding embedding similarity score is close toâ€¬
â€ª1, and the L2 norm of ğ‘(ğ‘–â€²)increases significantly [39, 42]. Simi-â€¬
â€ªlar observations can be made for the contrastive augmentationsâ€¬
â€ªI(z,hğ›¼)and I(z,hğ›½)using the learnable augmenter. Thus, ourâ€¬
â€ªdisentangled contrastive learning paradigm is capable of seekingâ€¬
â€ªhard negative samples to enhance model optimization.â€¬
â€ªIn addition, we further justify the effectiveness of our modelâ€¬
â€ªdesign for capturing the implicit cross-intent dependency via theâ€¬
â€ªgradient propagation. Here, we discuss how the encoding process ofâ€¬
â€ªdisentangled representation r(ğ‘¢)â€¬
â€ªğ‘– can propagate gradients to latentâ€¬
â€ªintent prototypes {cğ‘˜â€¬
â€ªğ‘¢}ğ¾â€¬
â€ªğ‘˜=1. Referring to Equation (7) and (9), weâ€¬
â€ªhave the following partial derivative:â€¬
â€ªğœ•r(ğ‘¢)â€¬
â€ªğ‘–â€¬
â€ª=â€¬
â€ªğœ•cğ‘¡â€¬
â€ªğ‘¢â€¬
â€ªï£® ï£¯ ï£¯ ï£¯ ï£¯ ï£¯ ï£¯ ï£¯ ï£¯ ï£°â€¬
â€ªğœ•(r(ğ‘¢)â€¬
â€ªğ‘– )1â€¬
â€ªğœ•(cğ‘¡â€¬
â€ªğ‘¢ )1Â·Â·Â·â€¬
â€ª.â€¬
â€ª.â€¬
â€ª.â€¬
â€ª.â€¬
â€ª.â€¬
â€ª.â€¬
â€ªğœ•(r(ğ‘¢)â€¬
â€ªğ‘– )ğ‘‘â€¬
â€ªğœ•(cğ‘¡â€¬
â€ªğ‘¢ )1Â·Â·Â·â€¬
â€ªğœ•(r(ğ‘¢)â€¬
â€ªğ‘– )1â€¬
â€ªğœ•(cğ‘¡â€¬
â€ªğ‘¢ )ğ‘‘â€¬
â€ª.â€¬
â€ª.â€¬
â€ª.â€¬
â€ªğœ•(r(ğ‘¢)â€¬
â€ªğ‘– )ğ‘‘â€¬
â€ªğœ•(cğ‘¡â€¬
â€ªğ‘¢ )ğ‘‘â€¬
â€ªï£¹ ï£º ï£º ï£º ï£º ï£º ï£º ï£º ï£º ï£», (21)â€¬
â€ªğœ•(r(ğ‘¢)â€¬
â€ªğ‘– )ğ‘šâ€¬
â€ª= ğ‘ƒğ‘¡â€¬
â€ªğœ•(cğ‘¡â€¬
â€ªğ‘¢)ğ‘›â€¬
â€ªğ¾â€¬
â€ªâˆ‘ï¸â€¬
â€ªğ‘˜=1â€¬
â€ªğ‘ƒğ‘˜[(e(ğ‘¢)â€¬
â€ªğ‘– )ğ‘›((cğ‘¡â€¬
â€ªğ‘¢)ğ‘š âˆ’(cğ‘˜â€¬
â€ªğ‘¢)ğ‘š)+I(ğ‘š= ğ‘›)]. (22)â€¬
â€ªğ‘ƒğ‘¡ is short for ğ‘ƒ(cğ‘¡â€¬
â€ªğ‘¢|e(ğ‘¢)â€¬
â€ªğ‘– ). As can be seen from the partial deriva-â€¬
â€ªtives, the intent-aware representations r(ğ‘¢)â€¬
â€ªğ‘– propagate gradientsâ€¬
â€ªto the latent intent prototype via the estimation of conditionalâ€¬
â€ªprobability ğ¾â€¬
â€ªğ‘˜ ğ‘ƒ(ğ‘¦,ğ‘ğ‘˜â€¬
â€ªğ‘¢,ğ‘ğ‘˜â€¬
â€ªğ‘£|ğ‘¢,ğ‘£). During the backward propagationâ€¬
â€ªprocess, the cross-intent embedding aggregation can propagateâ€¬
â€ªgradients to all latent intents with the learned relevance weights.â€¬
â€ªTherefore, the gradient learning enhanced by our auxiliary con-â€¬
â€ªtrastive learning tasks is appropriately distributed to all latent in-â€¬
â€ªtents, which facilitates the cross-intent dependency modeling andâ€¬
â€ªhelps to capture accurate user preferences for recommendation.â€¬
â€ªTime Complexity Analysis. We analyze the time complexity ofâ€¬
â€ªdifferent components in our DCCF from the following aspects: i)â€¬
â€ªThe graph-based message passing procedure takes O(ğ¿Ã—|A|Ã—â€¬
â€ªğ‘‘)time, where ğ¿ denotes the number of graph neural layers forâ€¬
â€ªmessage passing. |A|represents the number of edges in the graphâ€¬
â€ªand ğ‘‘ is the dimensionality of user/item representations. ii) Theâ€¬
â€ªintent-aware information aggregation component takes O(ğ¿Ã—(ğ¼+â€¬
â€ªğ½)Ã—ğ¾Ã—ğ‘‘)time complexity, where ğ¾ denotes the number of latentâ€¬
â€ªintents. iii) Due to local- and global-based adaptive augmentation, itâ€¬
â€ªtakes O(2Ã—ğ¿Ã—|A|Ã—ğ‘‘)time complexity to generate two augmentedâ€¬
â€ªviews for self-supervision. iv) To calculate the contrastive learningâ€¬
â€ªobjective, the cost is O(ğ¿Ã—ğµÃ—(ğ¼+ğ½)Ã—ğ‘‘), where ğµis the numberâ€¬
â€ªof users/items included in a single mini-batch.â€¬
â€ªSIGIRâ€™23, July 23â€“27, 2023, Taipei, Taiwan Table 1: Statistics of the experimental datasets.â€¬
â€ªXubin Ren, Lianghao Xia, Jiashu Zhao, Dawei Yin, & Chao Huangâ€¬
â€ªDataset #Users #Items #Interactions Densityâ€¬
â€ªGowalla 50,821 57,440 1,172,425 4.0ğ‘’âˆ’4â€¬
â€ªAmazon-book 78,578 77,801 2,240,156 3.7ğ‘’âˆ’4â€¬
â€ªTmall 47,939 41,390 2,357,450 1.2ğ‘’âˆ’3â€¬
â€ª4 EVALUATIONâ€¬
â€ªIn this section, we perform experiments to evaluate our DCCF onâ€¬
â€ªdifferent datasets by answering the following research questions:â€¬
â€ªâ€¢RQ1: Does our proposed DCCF outperform various recommen-â€¬
â€ªdation solutions under different experimental settings?â€¬
â€ªâ€¢RQ2: Do the designed key components benefit the representationâ€¬
â€ªlearning of our DCCF in achieving performance improvement?â€¬
â€ªâ€¢RQ3: Is our proposed model effective in alleviating the dataâ€¬
â€ªsparsity issues with our disentangled self-supervised signals?â€¬
â€ªâ€¢RQ4: What is the impact of the number of latent intents?â€¬
â€ªâ€¢RQ5: How does our DCCF perform w.r.t training efficiency?â€¬
â€ª4.1 Experimental Settingsâ€¬
â€ª4.1.1 Datasets. We evaluate our model performance on publicâ€¬
â€ªdatasets: Gowalla: This dataset is collected from the Gowalla plat-â€¬
â€ªform to record check-in relations between users and different lo-â€¬
â€ªcations based on mobility traces. Amazon-book: This dataset in-â€¬
â€ªcludes rating behaviors of users over products with book categoryâ€¬
â€ªon Amazon. Tmall: It contains customer purchase behaviors fromâ€¬
â€ªthe online retailer Tmall. Table 1 summarizes the dataset statistics.â€¬
â€ª4.1.2 Evaluation Protocols and Metrics. To alleviate the biasâ€¬
â€ªof negative item instance sampling, we follow the all-rank proto-â€¬
â€ªcol [13, 36, 39] over all items to measure the accuracy of our rec-â€¬
â€ªommendation results. We use two widely adopted ranking-basedâ€¬
â€ªmetrics to evaluate the performance of all methods, namely Re-â€¬
â€ªcall@N and NDCG (Normalized Discounted Cumulative Gain)@N.â€¬
â€ª4.1.3 Baseline Methods. We include five groups of baseline meth-â€¬
â€ªods for comprehensive comparison, as detailed below.â€¬
â€ª(i) Factorization-based Method.â€¬
â€ªâ€¢NCF [14]. This method replaces the inner product in MF withâ€¬
â€ªa multi-layer perceptron to estimate user-item interactions. Forâ€¬
â€ªcomparison, we include the NeuMF version.â€¬
â€ª(ii) Autoencoder-based Method.â€¬
â€ªâ€¢AutoR [23]. It reconstructs user-item interactions based on theâ€¬
â€ªautoencoder to obtain user preference for non-interacted items.â€¬
â€ª(iii) Recommendation with Graph Neural Network.â€¬
â€ªâ€¢NGCF [32]. This method designs the propagation rule to injectâ€¬
â€ªcollaborative signals into the embedding process of recommenda-â€¬
â€ªtion, which is beneficial for capturing higher-order connectivity.â€¬
â€ªâ€¢LightGCN [13]. This method simplifies the message passingâ€¬
â€ªrule of GCN by linearly propagate user/item embeddings on theâ€¬
â€ªinteraction graph for collaborative filtering.â€¬
â€ª(iv) Disentangled Multi-Intent Recommender Systems.â€¬
â€ªâ€¢DisenGCN [19]. This method proposes a neighborhood routingâ€¬
â€ªmechanism to learn disentangled node representation. The dot-â€¬
â€ªproduct is used to predict the interaction likelihood.â€¬
â€ªâ€¢DisenHAN [36]. It disentangles user/item representations intoâ€¬
â€ªdifferent aspects (i.e., latent intents) and then aggregates infor-â€¬
â€ªmation from various aspects with attention for recommendation.â€¬
â€ªâ€¢CDR [6]. This method utilizes a userâ€™s noisy multi-feedback toâ€¬
â€ªmine user intentions and improves the training process throughâ€¬
â€ªcurriculum learning. We implement it with implicit feedback.â€¬
â€ªâ€¢DGCF [34]. This method generates the intent-aware graph byâ€¬
â€ªmodeling a distribution over intents for each interaction and thusâ€¬
â€ªlearns disentangled representations.â€¬
â€ªâ€¢DGCL [16]. This method proposes a factor-wise discriminationâ€¬
â€ªobjective to learn disentangled representations. We implement itâ€¬
â€ªto learn disentangled representations of nodes and make user-â€¬
â€ªitem interaction prediction using inner products.â€¬
â€ª(v) Self-Supervised Learning for Recommendation.â€¬
â€ªâ€¢SLRec [45]. This method proposes a multi-task self-supervisedâ€¬
â€ªlearning framework to address the label sparsity problem in large-â€¬
â€ªscale item recommender system.â€¬
â€ªâ€¢SGL-ED/ND [39]. This method reinforces user/item representa-â€¬
â€ªtion learning with GNNs by applying an auxiliary self-supervisedâ€¬
â€ªcontrastive learning task through data augmentation, namelyâ€¬
â€ªedge drop (ED) or node drop (ND).â€¬
â€ªâ€¢HCCF [42]. It jointly captures local and global collaborativeâ€¬
â€ªrelations under a hypergraph neural network, and designs cross-â€¬
â€ªview contrastive learning for augmentation.â€¬
â€ªâ€¢LightGCL [2]. It is a lightweight graph contrastive learningâ€¬
â€ªframework by leveraging singular value decomposition to gener-â€¬
â€ªate augmented view for embedding contrasting.â€¬
â€ª4.1.4 Hyperparameter Settings. We implement our DCCF usingâ€¬
â€ªPyTorch and use Adam [15] as optimizer with learning rate 1ğ‘’âˆ’3â€¬
â€ª.â€¬
â€ªThe number of latent intent prototypes ğ¾is selected from the rangeâ€¬
â€ªof {32,64,128,256}with ğ¾= 128 by default. ğœ†1, ğœ†2 and ğœ†3 areâ€¬
â€ªtuned from the range of [0.001,0.025,0.1,0.2], [2.5ğ‘’âˆ’5â€¬
â€ª,5ğ‘’âˆ’4â€¬
â€ª,5ğ‘’âˆ’3],â€¬
â€ª[2.5ğ‘’âˆ’5â€¬
â€ª,5ğ‘’âˆ’4â€¬
â€ª,5ğ‘’âˆ’3], respectively. To evaluate baseline performanceâ€¬
â€ªwith fair settings, latent embedding dimensionality ğ‘‘and batchsizeâ€¬
â€ªis set as 32 and 10240 for all compared methods. For graph-basedâ€¬
â€ªmodels, the number of propagation layers is chosen from {1,2,3}.â€¬
â€ªDetailed model implementation of our DCCF can be found in ourâ€¬
â€ªreleased source code in the Abstract Section.â€¬
â€ª4.2 Performance Comparison (RQ1)â€¬
â€ªTable 2 shows the performance comparison of different methodsâ€¬
â€ªon all datasets. To validate the significant performance improve-â€¬
â€ªment achieved by our DCCF model, the p-value is provided. Fromâ€¬
â€ªevaluation results, we summarize the following observations:â€¬
â€ªâ€¢DCCF consistently outperforms all baselines on all three datasets.â€¬
â€ªThrough disentangled contrastive learning, DCCF improves theâ€¬
â€ªgeneralization and robustness of recommenders by offering moreâ€¬
â€ªinformative representations. We attribute the significant per-â€¬
â€ªformance gain of DCCF to two key aspects: (i) DCCF effec-â€¬
â€ªtively alleviates the data sparsity issue by distilling disentangledâ€¬
â€ªself-supervised signals as supplementary training tasks. (ii) Ourâ€¬
â€ªproposed parameterized graph mask generator is beneficial forâ€¬
â€ªachieving adaptive self-supervision against data noise redun-â€¬
â€ªdancy, which further improves the representation robustness.â€¬
â€ªDisentangled Contrastive Collaborative Filtering SIGIRâ€™23, July 23â€“27, 2023, Taipei, Taiwanâ€¬
â€ªTable 2: Recommendation performance of all compared methods on different datasets in terms of Recall and NDCG.â€¬
â€ªData Gowalla Amazon-book Tmallâ€¬
â€ªMetrics Recall@20 Recall@40 NDCG@20 NDCG@40 Recall@20 Recall@40 NDCG@20 NDCG@40 Recall@20 Recall@40 NDCG@20 NDCG@40â€¬
â€ªNCF 0.1247 0.1910 0.0659 0.0832 0.0468 0.0771 0.0336 0.0438 0.0383 0.0647 0.0252 0.0344â€¬
â€ªAutoR 0.1409 0.2142 0.0716 0.0905 0.0546 0.0914 0.0354 0.0482 0.0336 0.0611 0.0203 0.0295â€¬
â€ªNGCF LightGCN 0.1413 0.2072 0.0813 0.0987 0.1799 0.2577 0.1053 0.1255 0.0532 0.0866 0.0388 0.0501 0.0732 0.1148 0.0544 0.0681 0.0420 0.0751 0.0250 0.0365â€¬
â€ª0.0555 0.0895 0.0381 0.0499â€¬
â€ªDisenGCN DisenHAN CDR DGCF DGCL 0.1379 0.2003 0.0798 0.0961 0.1437 0.2079 0.0829 0.0997 0.1364 0.1943 0.0812 0.0963 0.1784 0.2515 0.1069 0.1259 0.1793 0.2483 0.1067 0.1247 0.0481 0.0776 0.0353 0.0451 0.0542 0.0865 0.0407 0.0513 0.0564 0.0887 0.0419 0.0526 0.0688 0.1073 0.0513 0.0640 0.0677 0.1057 0.0506 0.0631 0.0422 0.0688 0.0285 0.0377â€¬
â€ª0.0416 0.0682 0.0283 0.0376â€¬
â€ª0.0520 0.0833 0.0356 0.0465â€¬
â€ª0.0544 0.0867 0.0372 0.0484â€¬
â€ª0.0526 0.0845 0.0359 0.0469â€¬
â€ªSLRec SGL-ED SGL-ND HCCF LightGCL 0.1529 0.2200 0.0926 0.1102 0.1809 0.2559 0.1067 0.1262 0.1814 0.2589 0.1065 0.1267 0.1818 0.2601 0.1061 0.1265 0.1825 0.2601 0.1077 0.1280 0.0544 0.0879 0.0374 0.0490 0.0774 0.1204 0.0578 0.0719 0.0722 0.1121 0.0542 0.0674 0.0824 0.1282 0.0625 0.0776 0.0836 0.1280 0.0643 0.0790 0.0549 0.0888 0.0375 0.0492â€¬
â€ª0.0574 0.0919 0.0393 0.0513â€¬
â€ª0.0553 0.0885 0.0379 0.0494â€¬
â€ª0.0623 0.0986 0.0425 0.0552â€¬
â€ª0.0632 0.0971 0.0444 0.0562â€¬
â€ªDCCF 0.1876 0.2644 0.1123 0.1323 0.0889 0.1343 0.0680 0.0829 0.0668 0.1042 0.0469 0.0598â€¬
â€ªp-val. 8.9ğ‘’âˆ’6 1.3ğ‘’âˆ’3 2.6ğ‘’âˆ’6 8.1ğ‘’âˆ’6 8.6ğ‘’âˆ’7 2.2ğ‘’âˆ’6 8.6ğ‘’âˆ’6 2.2ğ‘’âˆ’6 2.6ğ‘’âˆ’7 1.4ğ‘’âˆ’7 8.6ğ‘’âˆ’7 1.8ğ‘’âˆ’7â€¬
â€ªTable 3: Ablation study on key components of DCCF (mea-â€¬
â€ªsured by ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™@20 and ğ‘ğ·ğ¶ğº@20) on different datasets.â€¬
â€ªLightGCNâ€¬
â€ªDGCFâ€¬
â€ªDGCLâ€¬
â€ªDCCFâ€¬
â€ªCategory Data Gowalla Amazon-book Tmallâ€¬
â€ªVariants Recall NDCG Recall NDCG Recall NDCGâ€¬
â€ªNDCG@40â€¬
â€ª0.10â€¬
â€ª0.08â€¬
â€ª0.06â€¬
â€ª0.04â€¬
â€ª0.02â€¬
â€ªLightGCNâ€¬
â€ªDGCFâ€¬
â€ªDGCLâ€¬
â€ªDCCFâ€¬
â€ªDME -Disen 0.1637 0.0975 0.0772 0.0580 0.0629 0.0437â€¬
â€ªRecall@40â€¬
â€ª0.25â€¬
â€ª0.20â€¬
â€ª0.15â€¬
â€ª0.10â€¬
â€ª0.05â€¬
â€ª0-10 10-20 20-30 30-40 40-50â€¬
â€ªInteraction Degreeâ€¬
â€ª0-10 10-20 20-30 30-40 40-50â€¬
â€ªInteraction Degreeâ€¬
â€ªPAM -LocalR -DisenR 0.1719 0.1015 0.1718 0.1016 0.0786 0.0593 0.0793 0.0597 0.0638 0.0446â€¬
â€ª0.0640 0.0447â€¬
â€ª(a) Performance w.r.t. different item groupsâ€¬
â€ªSSL -DisenG -AllAda 0.1763 0.1053 0.1845 0.1096 0.0829 0.0635 0.0833 0.0632 0.0644 0.0449â€¬
â€ª0.0651 0.0452â€¬
â€ªLightGCNâ€¬
â€ªDGCFâ€¬
â€ªDGCLâ€¬
â€ªDCCFâ€¬
â€ªLightGCNâ€¬
â€ªDGCFâ€¬
â€ªDGCLâ€¬
â€ªDCCFâ€¬
â€ªDCCF 0.1876 0.1123 0.0889 0.0680 0.0668 0.0469â€¬
â€ªRecall@40â€¬
â€ª0.30â€¬
â€ª0.25â€¬
â€ª0.20â€¬
â€ªâ€¢Although data augmentation techniques are also proposed inâ€¬
â€ªcurrent SSL-based methods (e.g., SGL, HCCF), our DCCF still out-â€¬
â€ªperforms them by a large margin. This is because simply learningâ€¬
â€ªaugmented representations at coarse-grained level cannot dis-â€¬
â€ªentangle latent intention factors behind user-item interactions.â€¬
â€ªIn addition, we notice that most SSL-based methods performâ€¬
â€ªbetter than conventional GNN-based approaches (e.g., LightGCN,â€¬
â€ªNGCF), which suggests the positive effects of SSL brings to GNN-â€¬
â€ªbased CF models. With our disentangled adaptive augmentation,â€¬
â€ªDCCF still pushes that boundary forward, achieving state-of-the-â€¬
â€ªart performance across all datasets.â€¬
â€ªâ€¢The performance improvement of DCCF over other disentangledâ€¬
â€ªrecommender systems (e.g., DGCF, DisenGCN, CDR) verifiesâ€¬
â€ªthat our approach is not limited to the label shortage issue. Theâ€¬
â€ªintegration of disentangled multi-intent encoding and contrastiveâ€¬
â€ªlearning results in better performance. Existing disentangledâ€¬
â€ªlearning solutions struggle to generate informative embeddingsâ€¬
â€ªin the face of insufficient training labels due to the overfittingâ€¬
â€ªeffect. Although DGCL attempts to use contrastive learning toâ€¬
â€ªencode latent factors into augmented representations, its non-â€¬
â€ªadaptive contrastive view generation makes it easily influencedâ€¬
â€ªby noise perturbation.â€¬
â€ª0-10 10-20 20-30 30-40 40-50â€¬
â€ªInteraction Degreeâ€¬
â€ªNDCG@40â€¬
â€ª0.14â€¬
â€ª0.13â€¬
â€ª0.12â€¬
â€ª0.11â€¬
â€ª0-10 10-20 20-30 30-40 40-50â€¬
â€ªInteraction Degreeâ€¬
â€ª(b) Performance w.r.t. different user groupsâ€¬
â€ªFigure 2: Performance comparison w.r.t. data sparsity overâ€¬
â€ªdifferent user/item groups on Gowalla data.â€¬
â€ª4.3 Ablation Study (RQ2)â€¬
â€ªIn this section, to verify the effectiveness of each component, weâ€¬
â€ªconduct an ablation study to examine the component-specific ben-â€¬
â€ªefits of our DCCF framework from three perspectives: (i) Disen-â€¬
â€ªtangled Multi-intent Encoding (DME); (ii) Parameterized Adaptiveâ€¬
â€ªMasking (PAM); (iii) Self-supervised Learning (SSL). The perfor-â€¬
â€ªmance results are reported in Table 3, and the variant details andâ€¬
â€ªimpact study are presented as follows:â€¬
â€ªâ€¢Disentangled Multi-intent Encoding (DME). We generateâ€¬
â€ªthe ablation model (-Disen) by removing the disentangled multi-â€¬
â€ªintent encoding module. The performance gap between DCCFâ€¬
â€ªand -Disen indicates the contribution of multi-intent representa-â€¬
â€ªtion encoding to the overall performance.â€¬
â€ªâ€¢Parameterized Adaptive Masking (PAM). To investigate theâ€¬
â€ªeffect of our parameterized adaptive masking, we create twoâ€¬
â€ªvariants: (i) -LocalR which removes implicit user-item relationâ€¬
â€ªlearning based on local relation embeddings; and (ii) -DisenR,â€¬
â€ªSIGIRâ€™23, July 23â€“27, 2023, Taipei, Taiwan Table 4: The embedding smoothness on Amazon-book andâ€¬
â€ªTmall data measured by MAD metric (the smaller the MADâ€¬
â€ªindicates more obvious the over-smoothing phenomenon).â€¬
â€ªEmbeddingâ€¬
â€ªTypeâ€¬
â€ªDCCF DCCF-CL DGCL DisenGCN LightGCNâ€¬
â€ªAmazon-bookâ€¬
â€ªUser Item 0.999 0.902 0.980 0.961 0.984â€¬
â€ª0.990 0.961 0.989 0.986 0.944â€¬
â€ªTmallâ€¬
â€ªUser Item 0.999 0.800 0.897 0.876 0.910â€¬
â€ª0.998 0.873 0.920 0.992 0.927â€¬
â€ªwhich removes the intent-based graph structure learning pro-â€¬
â€ªcess. The results show that both variants lead to a performanceâ€¬
â€ªdegradation, indicating the necessity of adaptive self-supervisedâ€¬
â€ªsignal distillation for contrastive augmentation.â€¬
â€ªâ€¢Self-Supervised Learning (SSL). We also examine the influ-â€¬
â€ªence of our disentangled contrastive learning on performanceâ€¬
â€ªby adjusting the incorporated self-supervised optimization ob-â€¬
â€ªjectives. Specifically, we creat two variants by removing agree-â€¬
â€ªments between the original graph representations with auxiliaryâ€¬
â€ªaugmented views: (i) disentangled global collaborative view (-â€¬
â€ªDisenG) and (ii) all augmented views with adaptive maskingâ€¬
â€ª(-AllAda). Our results show that DCCF achieves the best per-â€¬
â€ªformance compared to these variants, further emphasizing theâ€¬
â€ªbenefits of integrating auxiliary self-supervised learning signalsâ€¬
â€ªfrom the global view of intent-aware collaborative relationshipsâ€¬
â€ªfor adaptive data augmentation.â€¬
â€ª4.4 In-Depth Analysis of DCCF (RQ3 & RQ4)â€¬
â€ª4.4.1 Performance w.r.t Data Sparsity. We further verify ifâ€¬
â€ªDCCF is robust to data sparsity issue. To do this, we divide usersâ€¬
â€ªand items into different groups based on the number of their in-â€¬
â€ªteractions, and separately measured recommendation accuracy forâ€¬
â€ªeach group. From the results in Figure 2, we make two main obser-â€¬
â€ªvations: (i) DCCF consistently outperforms several representativeâ€¬
â€ªbaselines (i.e., LightGCN, DGCL, DGCF) by providing better recom-â€¬
â€ªmendation results for both inactive and active users. This indicatesâ€¬
â€ªthe benefits of our generated self-supervised signals in alleviatingâ€¬
â€ªsparse data issues. While DGCL conducts factor-wise alignmentâ€¬
â€ªwith contrastive learning, the interaction noise and bias can still im-â€¬
â€ªpair the disentangled representation learning for latent factors.(ii)â€¬
â€ªWe notice that the performance gap between DCCF and the com-â€¬
â€ªpared methods is still apparent on low-degree items. This is becauseâ€¬
â€ªthe baseline DGCF only focuses on splitting the user representationâ€¬
â€ªinto multiple intent-aware embeddings, which can easily lead toâ€¬
â€ªrecommending high-degree items and neglect the long-tail items. Inâ€¬
â€ªcontrast, our DCCF enhances the interaction modeling on long-tailâ€¬
â€ªitems through effective self-supervised information.â€¬
â€ª4.4.2 Impact of the Number of Intent Prototypes. To investi-â€¬
â€ªgate the impact of the number of latent intents on model perfor-â€¬
â€ªmance, we select this parameter from the range {32,64,128,256}â€¬
â€ªand re-train the model. The results are shown in Figure 3. It isâ€¬
â€ªclear that as the number of intents increases, the performance ofâ€¬
â€ªthe model also improves. However, when the number of intentsâ€¬
â€ªXubin Ren, Lianghao Xia, Jiashu Zhao, Dawei Yin, & Chao Huangâ€¬
â€ªDecrease of NDCG@20 (%)â€¬
â€ªDecrease of Recall@20 (%)â€¬
â€ª0.0â€¬
â€ª2.5â€¬
â€ª5.0â€¬
â€ª7.5â€¬
â€ª10.0â€¬
â€ª0.0â€¬
â€ª2.5â€¬
â€ª5.0â€¬
â€ª7.5â€¬
â€ª10.0â€¬
â€ªGowallaâ€¬
â€ªAmazon-bookâ€¬
â€ªTmallâ€¬
â€ª32 64 128 256â€¬
â€ªNumber of Latent Intentsâ€¬
â€ªGowallaâ€¬
â€ªAmazon-bookâ€¬
â€ªTmallâ€¬
â€ªDecrease of NDCG@40 (%)â€¬
â€ªDecrease of Recall@40 (%)â€¬
â€ª0.0â€¬
â€ª2.5â€¬
â€ª5.0â€¬
â€ª7.5â€¬
â€ª0.0â€¬
â€ª2.5â€¬
â€ª5.0â€¬
â€ª7.5â€¬
â€ªGowallaâ€¬
â€ªAmazon-bookâ€¬
â€ªTmallâ€¬
â€ª32 64 128 256â€¬
â€ªNumber of Latent Intentsâ€¬
â€ªGowallaâ€¬
â€ªAmazon-bookâ€¬
â€ªTmallâ€¬
â€ª32 64 128 256â€¬
â€ªNumber of Latent Intentsâ€¬
â€ª32 64 128 256â€¬
â€ªNumber of Latent Intentsâ€¬
â€ªFigure 3: Performance w.r.t the number of latent intents.â€¬
â€ªincreases from 128 to 256, the performance improvement is limited,â€¬
â€ªand even degrades on the Tmall dataset. To further understand thisâ€¬
â€ªphenomenon, we transform the intent prototypes into 2D space forâ€¬
â€ªvisualization using t-SNE [27] and then clustered them. As shownâ€¬
â€ªin Figure 4, when the number of intents is 128, some latent intentsâ€¬
â€ªhave begun to cluster together. Further increasing the number ofâ€¬
â€ªintents causes intent redundancy with too fine-grained latent factorâ€¬
â€ªgranularity and introduces noise into learning representations.â€¬
â€ª4.4.3 Robustness of DCCF in Alleviating Over-Smoothing.â€¬
â€ªTo validate the effectiveness of DCCF in alleviating over-smoothing,â€¬
â€ªwe calculate the Mean Average Distance (MAD) [5, 42] over en-â€¬
â€ªcoded user/item embeddings of DCCF and the variant DCCF-CL,â€¬
â€ªwhich disables the cross-view contrastive learning module. We alsoâ€¬
â€ªcalculate the MAD of several representative baseline methods (i.e.,â€¬
â€ªDGCL, DisenGCN, LightGCN) for comparison. Note that all the em-â€¬
â€ªbeddings were normalized before calculating MAD for fair compar-â€¬
â€ªison. The results are shown in Table 4. We notice that by removingâ€¬
â€ªthe SSL objective, the over-smoothing phenomenon becomes moreâ€¬
â€ªpronounced, which suggests the effectiveness of our contrastiveâ€¬
â€ªlearning component in addressing the over-smoothing problem.â€¬
â€ªMoreover, all the baselines have lower MAD than our DCCF, in-â€¬
â€ªdicating that DCCF is capable of alleviating the over-smoothingâ€¬
â€ªissue in the widely-adopted GNN architecture. Our disentangledâ€¬
â€ªcontrastive learning approach achieves better representation uni-â€¬
â€ªformity in recommendation compared to the baselines.â€¬
â€ªTable 5: Computational cost evaluation in terms of per-epochâ€¬
â€ªtraining time (seconds) on Gowalla, Amazon, and Tmall data.â€¬
â€ªModel DisenGCN DGCF DisenHAN DGCL Oursâ€¬
â€ªGowalla Amazon-book Tmall 19.1s 25.1s 16.8s 9.3s 42.2s 49.6s 30.6s 12.4s 43.5s 51.6s 29.8s 12.0s 12.4sâ€¬
â€ª18.9sâ€¬
â€ª18.8sâ€¬
â€ª4.5 Model Training Efficiency Study (RQ5)â€¬
â€ªIn this section, we investigate the model efficiency of our DCCF inâ€¬
â€ªterms of training computational cost on all datasets. The experi-â€¬
â€ªments were conducted on a server with system configurations of anâ€¬
â€ªIntel Xeon Gold 6330 CPU, NVIDIA RTX 3090. As shown in Table 5,â€¬
â€ªwe compare our DCCF with disentangled recommender systemsâ€¬
â€ª(e.g., DGCF and DisenHAN) and found that our DCCF achievesâ€¬
â€ªcomparable training efficiency in all cases. Specifically, while DGCFâ€¬
â€ªDisentangled Contrastive Collaborative Filtering 40â€¬
â€ª20â€¬
â€ª0â€¬
â€ª20â€¬
â€ª40â€¬
â€ª40â€¬
â€ª20â€¬
â€ª0â€¬
â€ª20â€¬
â€ª40â€¬
â€ª40â€¬
â€ª20â€¬
â€ª0â€¬
â€ª20â€¬
â€ª40â€¬
â€ª50 25 0 25â€¬
â€ªGowallaâ€¬
â€ª40 20 0 20 40â€¬
â€ªAmazon-bookâ€¬
â€ª50 25 0 25â€¬
â€ªTmallâ€¬
â€ª(a) User intent prototypesâ€¬
â€ª40â€¬
â€ª20â€¬
â€ª0â€¬
â€ª20â€¬
â€ª40â€¬
â€ª30â€¬
â€ª20â€¬
â€ª10â€¬
â€ª0â€¬
â€ª10â€¬
â€ª20â€¬
â€ª30â€¬
â€ª40â€¬
â€ª20â€¬
â€ª0â€¬
â€ª20â€¬
â€ª40â€¬
â€ª20 0 20â€¬
â€ªGowallaâ€¬
â€ª40 20 0 20 40â€¬
â€ªAmazon-bookâ€¬
â€ª40 20 0 20â€¬
â€ªTmallâ€¬
â€ª(b) Item intent prototypesâ€¬
â€ªFigure 4: Distribution of latent intent prototypes.â€¬
â€ª>3hopsâ€¬
â€ªğ’–ğŸğŸğŸ“ğŸ“ ğ’–ğŸ‘ğŸğŸ–ğŸ“ğŸ”â€¬
â€ª0.83 0.82â€¬
â€ªweightâ€¬
â€ª( ğŸğŸğŸ)â€¬
â€ª0.82â€¬
â€ª0.83â€¬
â€ª0.84â€¬
â€ª0.82â€¬
â€ª0.82â€¬
â€ª0.83â€¬
â€ª0.83â€¬
â€ª0.83â€¬
â€ªğŸğŸğŸ” ğŸğŸ— ğŸ‘ğŸ” ğŸ–ğŸ ğŸ’ğŸ”â€¬
â€ªğŸ”ğŸ—â€¬
â€ªuser latent intent prototypesâ€¬
â€ª(with the highest weight)â€¬
â€ªğ’–ğŸğŸğŸ“ğŸ“â€¬
â€ªğ’–ğŸ‘ğŸğŸ–ğŸ“ğŸ”â€¬
â€ªCategories thatâ€¬
â€ªthem most interacted withâ€¬
â€ª16â€¬
â€ª13â€¬
â€ª12â€¬
â€ª34 20â€¬
â€ª14â€¬
â€ªnum. ofâ€¬
â€ªinteractionsâ€¬
â€ªğŸğŸ‘ğŸ”ğŸ•â€¬
â€ªğŸğŸğŸğŸ’â€¬
â€ªğŸ”ğŸ’ğŸ“â€¬
â€ªcategory idâ€¬
â€ªFigure 5: Case study of intent-aware global user relations.â€¬
â€ªNon-locally connected users (ğ‘¢1155 and ğ‘¢32856) can be identi-â€¬
â€ªfied with similar user preference (large item category over-â€¬
â€ªlap) via our learned disentangled representations.â€¬
â€ªsplits the user embedding into intent-aware vectors to reduce em-â€¬
â€ªbedding size, the heavy cost of DGCF stems from the recursivelyâ€¬
â€ªrouting mechanism for information propagation. It requires extraâ€¬
â€ªtime to process multiple iterations to obtain intent-relevant weights.â€¬
â€ªIn DisenHAN, the time-consuming graph attention network bringsâ€¬
â€ªhigh cost due to the need for computing the attention weights.â€¬
â€ª4.6 Case Studyâ€¬
â€ªGlobal Intent-aware Semantic Dependency. In this section, weâ€¬
â€ªexamine the potential ability of our DCCF in capturing the globalâ€¬
â€ªintent-aware semantic dependencies among users. To achieve thisâ€¬
â€ªgoal, we showe some concrete examples in Figure 5 to visualize theâ€¬
â€ªintent-aware user preferences learned by our DCCF. We observeâ€¬
â€ªthat ğ‘¢1155 and ğ‘¢32856 share very similar intent-aware preferences, asâ€¬
â€ªshown with intent prototype-specific user weights, despite not be-â€¬
â€ªing locally connected on the interaction graph. After investigatingâ€¬
â€ªtheir interaction patterns, we observe a significant overlap betweenâ€¬
â€ªthe categories (categories 29,36,and 69) of the items they interactedâ€¬
â€ªwith, indicating the high semantic relatedness of their interactionâ€¬
â€ªbehaviors. Therefore, in addition to local collaborative relations,â€¬
â€ªthe global intent-aware user dependencies can be preserved withâ€¬
â€ªSIGIRâ€™23, July 23â€“27, 2023, Taipei, Taiwanâ€¬
â€ªCate. 1024 (19 interactions, avg. ğŸ. ğŸğŸğŸ“ğŸ”) Cate. 645 (10 interactions, avg. ğŸ. ğŸğŸğŸ’ğŸ)â€¬
â€ªğ’ŠğŸğŸğŸ‘ğŸ—ğŸ– ğ’ŠğŸğŸ•ğŸ–ğŸ– ğ’ŠğŸğŸ–ğŸğŸğŸ ğ’ŠğŸğŸ–ğŸ”ğŸ’ğŸ ğ’ŠğŸ‘ğŸ‘ğŸ•ğŸ•ğŸ ğ’ŠğŸ‘ğŸ‘ğŸ”ğŸ—ğŸ” ğ’ŠğŸ’ğŸğŸ’ğŸ•ğŸ ğ’ŠğŸğŸğŸ”ğŸ—ğŸ• ğ’ŠğŸğŸ‘ğŸğŸğŸ–â€¬
â€ªremain items remain itemsâ€¬
â€ª0.0282 0.0281 0.0275 0.0270â€¬
â€ª0.0259 0.0254â€¬
â€ª0.0259â€¬
â€ª0.0270 0.0273â€¬
â€ªaugmented relation valueâ€¬
â€ªin matrix (Eq. 10~11)â€¬
â€ªğ’–ğŸğŸğŸ“ğŸ”ğŸ•â€¬
â€ª0.0226â€¬
â€ª0.0182â€¬
â€ª0.0221â€¬
â€ª0.0268â€¬
â€ª0.0186â€¬
â€ª0.0178â€¬
â€ª0.0185â€¬
â€ª0.0239â€¬
â€ª0.0232â€¬
â€ªğ’ŠğŸğŸğŸ“ğŸ” ğ’ŠğŸ’ğŸ”ğŸ’ğŸ’ ğ’ŠğŸ”ğŸğŸ•ğŸ’ ğ’ŠğŸğŸğŸğŸğŸ ğ’ŠğŸ‘ğŸ“ğŸ–ğŸ’ğŸ‘ ğ’ŠğŸ‘ğŸ’ğŸ•ğŸ‘ğŸ–â€¬
â€ªCate. 299 Cate. 676 Cate. 1 Cate. 1195 Cate. 338 Cate. 1264â€¬
â€ªğ’ŠğŸ‘ğŸ’ğŸğŸğŸ• ğ’ŠğŸğŸ–ğŸğŸğŸ• ğ’ŠğŸğŸğŸğŸ’ğŸ“â€¬
â€ªremain itemsâ€¬
â€ªCate. 1367 (7 interactions, avg. ğŸ. ğŸğŸğŸğŸ’)â€¬
â€ªonly one interaction in each categoryâ€¬
â€ªFigure 6: Case study of intent-aware adaptive augmentationâ€¬
â€ªover the user-item relation matrix. User interacted items areâ€¬
â€ªgrouped in terms of their categories. The value of the learnedâ€¬
â€ªuser-item connectivity weight is consistent with the userâ€¬
â€ªpreference degree, i.e., the higher user-item weight encodedâ€¬
â€ªby DCCF indicates stronger user preference.â€¬
â€ªour encoded disentangled user representations.â€¬
â€ªIntent-aware Adaptive Augmentation We further analyze the ra-â€¬
â€ªtionality of our intent-aware adaptive augmentation over user-itemâ€¬
â€ªrelations. As shown in Figure 6, we grouped the interacted items ofâ€¬
â€ªuser ğ‘¢22567 based on categories (e.g., category 1024, 645). After per-â€¬
â€ªforming adaptive augmentation over the user-item relation matrix,â€¬
â€ªthe implicit dependency weight between each user-item pair wasâ€¬
â€ªlearned through our contrastive intent disentanglement. The valueâ€¬
â€ªof the learned user-item connectivity weight determines the userâ€™sâ€¬
â€ªpreference degree over this item. We notice that a higher user-itemâ€¬
â€ªrelation weight (e.g., 0.0282 or 0.0273) indicates a stronger interac-â€¬
â€ªtion preference over category-specific items, which is consistentâ€¬
â€ªwith the observation of the category-specific interaction frequencyâ€¬
â€ªof ğ‘¢22567. For example, the highest item correlation weight (i.e.,â€¬
â€ª0.0282) is generated from the categorical items that ğ‘¢22567 inter-â€¬
â€ªacted with the most. This observation further demonstrates theâ€¬
â€ªeffectiveness of our disentangled contrastive augmentation, whichâ€¬
â€ªis easily adaptable to different user-item interaction environments.â€¬
â€ª5 CONCLUSIONâ€¬
â€ªThis paper proposes a disentangled contrastive learning method forâ€¬
â€ªrecommendation that explores latent factors underlying implicit in-â€¬
â€ªtents for interactions. We introduce a graph structure learning layerâ€¬
â€ªthat enables adaptive interaction augmentation based on learnedâ€¬
â€ªdisentangled user (item) intent-aware dependencies. Along the aug-â€¬
â€ªmented intent-aware graph structures, we propose an intent-awareâ€¬
â€ªcontrastive learning scheme that brings the benefits of disentangledâ€¬
â€ªself-supervision signals. Our extensive experiments validate theâ€¬
â€ªeffectiveness of our proposed model on different recommendationâ€¬
â€ªdatasets. For future work, one potential extension is to integrateâ€¬
â€ªdisentangled representation learning with causal analysis to ad-â€¬
â€ªdress the bias issues of noisy interaction data. Additionally, byâ€¬
â€ªconsidering the diverse nature of user characteristics, personalizedâ€¬
â€ªaugmentation may further enhance the power of contrastive learn-â€¬
â€ªing for customized graph perturbing operations in recommenders.â€¬
â€ªBy tailoring the augmentation operations to the specific user char-â€¬
â€ªacteristics, we may better capture the individual preferences.â€¬
â€ªSIGIRâ€™23, July 23â€“27, 2023, Taipei, Taiwan REFERENCESâ€¬
â€ª[1] Shoshana Abramovich and Lars-Erik Persson. 2016. Some new estimates of theâ€¬
â€ªâ€™Jensen gapâ€™. Journal of Inequalities and Applications 2016, 1 (2016), 1â€“9.â€¬
â€ª[2] Xuheng Cai, Chao Huang, Lianghao Xia, and Xubin Ren. 2023. LightGCL: Simpleâ€¬
â€ªYet Effective Graph Contrastive Learning for Recommendation. In ICLR.â€¬
â€ª[3] Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, Depengâ€¬
â€ªJin, and Yong Li. 2021. Sequential recommendation with graph neural networks.â€¬
â€ªIn SIGIR. 378â€“387.â€¬
â€ª[4] Chong Chen, Min Zhang, Weizhi Ma, Yiqun Liu, and Shaoping Ma. 2020. Jointlyâ€¬
â€ªnon-sampling learning for knowledge graph enhanced recommendation. In SIGIR.â€¬
â€ª189â€“198.â€¬
â€ª[5] Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, and Xu Sun. 2020. Measuringâ€¬
â€ªand relieving the over-smoothing problem for graph neural networks from theâ€¬
â€ªtopological view. In AAAI, Vol. 34. 3438â€“3445.â€¬
â€ª[6] Hong Chen, Yudong Chen, Xin Wang, Ruobing Xie, Rui Wang, Feng Xia, andâ€¬
â€ªWenwu Zhu. 2021. Curriculum Disentangled Recommendation with Noisy Multi-â€¬
â€ªfeedback. NeurIPS 34, 26924â€“26936.â€¬
â€ª[7] Lei Chen, Le Wu, Richang Hong, Kun Zhang, and Meng Wang. 2020. Revisitingâ€¬
â€ªGraph Based Collaborative Filtering: A Linear Residual Graph Convolutionalâ€¬
â€ªNetwork Approach. In AAAI, Vol. 34. 27â€“34.â€¬
â€ª[8] Mengru Chen, Chao Huang, Lianghao Xia, Wei Wei, Yong Xu, and Ronghuaâ€¬
â€ªLuo. 2023. Heterogeneous Graph Contrastive Learning for Recommendation. Inâ€¬
â€ªWSDM. 544â€“552.â€¬
â€ª[9] Yongjun Chen, Zhiwei Liu, Jia Li, Julian McAuley, and Caiming Xiong. 2022. Intentâ€¬
â€ªcontrastive learning for sequential recommendation. In WWW. 2172â€“2182.â€¬
â€ª[10] Yudong Chen, Xin Wang, Miao Fan, Jizhou Huang, Shengwen Yang, et al. 2021.â€¬
â€ªCurriculum meta-learning for next POI recommendation. In KDD. 2692â€“2702.â€¬
â€ª[11] Yu Chen, Lingfei Wu, and Mohammed Zaki. 2020. Iterative deep graph learningâ€¬
â€ªfor graph neural networks: Better and robust node embeddings. NeurIPS (2020),â€¬
â€ª19314â€“19326.â€¬
â€ª[12] Xiang Gao, Meera Sitharam, and Adrian E Roitberg. 2019. Bounds on the Jensenâ€¬
â€ªgap, and implications for mean-concentrated distributions. AJMAA 16, 14 (2019),â€¬
â€ª1â€“16.â€¬
â€ª[13] Xiangnan He, Kuan Deng, Xiang Wang, et al. 2020. Lightgcn: Simplifying andâ€¬
â€ªpowering graph convolution network for recommendation. In SIGIR. 639â€“648.â€¬
â€ª[14] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Sengâ€¬
â€ªChua. 2017. Neural collaborative filtering. In WWW. 173â€“182.â€¬
â€ª[15] Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Opti-â€¬
â€ªmization. In ICLR.â€¬
â€ª[16] Haoyang Li, Xin Wang, Ziwei Zhang, Zehuan Yuan, Hang Li, and Wenwu Zhu.â€¬
â€ª2021. Disentangled contrastive learning on graphs. NeurIPS 34 (2021), 21872â€“â€¬
â€ª21884.â€¬
â€ª[17] Zihan Lin, Changxin Tian, Yupeng Hou, and Wayne Xin Zhao. 2022. Improvingâ€¬
â€ªGraph Collaborative Filtering with Neighborhood-enriched Contrastive Learning.â€¬
â€ªIn WWW. 2320â€“2329.â€¬
â€ª[18] Dongsheng Luo, Wei Cheng, Wenchao Yu, Bo Zong, Jingchao Ni, Haifeng Chen,â€¬
â€ªand Xiang Zhang. 2021. Learning to drop: Robust graph neural network viaâ€¬
â€ªtopological denoising. In WSDM. 779â€“787.â€¬
â€ª[19] Jianxin Ma, Peng Cui, Kun Kuang, Xin Wang, and Wenwu Zhu. 2019. Disentangledâ€¬
â€ªgraph convolutional networks. In ICML. PMLR, 4212â€“4221.â€¬
â€ª[20] Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, and Wenwu Zhu. 2019. Learn-â€¬
â€ªing disentangled representations for recommendation. In NeurIPS. 5711â€“5722.â€¬
â€ª[21] Shanlei Mu, Yaliang Li, Wayne Xin Zhao, Siqing Li, and Ji-Rong Wen. 2021.â€¬
â€ªKnowledge-Guided Disentangled Representation Learning for Recommenderâ€¬
â€ªSystems. Transactions on Information Systems (TOIS) 40, 1 (2021), 1â€“26.â€¬
â€ª[22] Zhen Peng, Wenbing Huang, Minnan Luo, et al. 2020. Graph representationâ€¬
â€ªlearning via graphical mutual information maximization. In WWW. 259â€“270.â€¬
â€ª[23] Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Lexing Xie. 2015.â€¬
â€ªAutorec: Autoencoders meet collaborative filtering. In WWW. 111â€“112.â€¬
â€ª[24] Weiping Song, Zhiping Xiao, Yifan Wang, Laurent Charlin, Ming Zhang, and Jianâ€¬
â€ªTang. 2019. Session-based social recommendation via dynamic graph attentionâ€¬
â€ªnetworks. In WSDM. 555â€“563.â€¬
â€ª[25] Jianing Sun, Zhaoyue Cheng, Saba Zuberi, Felipe PÃ©rez, and Maksims Volkovs.â€¬
â€ª2021. HGCF: Hyperbolic Graph Convolution Networks for Collaborative Filtering.â€¬
â€ªXubin Ren, Lianghao Xia, Jiashu Zhao, Dawei Yin, & Chao Huangâ€¬
â€ªIn WWW. 593â€“601.â€¬
â€ª[26] Changxin Tian, Yuexiang Xie, Yaliang Li, Nan Yang, and Wayne Xin Zhao. 2022.â€¬
â€ªLearning to Denoise Unreliable Interactions for Graph Collaborative Filtering. Inâ€¬
â€ªSIGIR. 122â€“132.â€¬
â€ª[27] Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE.â€¬
â€ªJournal of machine learning research 9, 11 (2008).â€¬
â€ª[28] Petar Velickovic, William Fedus, William L Hamilton, Pietro LiÃ², Yoshua Bengio,â€¬
â€ªand R Devon Hjelm. 2019. Deep Graph Infomax.. In ICLR.â€¬
â€ª[29] Tan Wang, Jianqiang Huang, Hanwang Zhang, and Qianru Sun. 2020. Visualâ€¬
â€ªcommonsense r-cnn. In CVPR. 10760â€“10770.â€¬
â€ª[30] Wenjie Wang, Fuli Feng, Xiangnan He, Xiang Wang, and Tat-Seng Chua. 2021.â€¬
â€ªDeconfounded recommendation for alleviating bias amplification. In KDD. 1717â€“â€¬
â€ª1725.â€¬
â€ª[31] Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, and Tat-Seng Chua. 2019. Kgat:â€¬
â€ªKnowledge graph attention network for recommendation. In KDD. 950â€“958.â€¬
â€ª[32] Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019.â€¬
â€ªNeural Graph Collaborative Filtering. In SIGIR.â€¬
â€ª[33] Xiang Wang, Tinglin Huang, Dingxian Wang, Yancheng Yuan, Zhenguang Liu,â€¬
â€ªXiangnan He, and Tat-Seng Chua. 2021. Learning intents behind interactionsâ€¬
â€ªwith knowledge graph for recommendation. In WWW. 878â€“887.â€¬
â€ª[34] Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, and Tat-Seng Chua.â€¬
â€ª2020. Disentangled graph collaborative filtering. In SIGIR. 1001â€“1010.â€¬
â€ª[35] Xiao Wang, Ruijia Wang, Chuan Shi, Guojie Song, et al. 2020. Multi-componentâ€¬
â€ªgraph convolutional collaborative filtering. In AAAI, Vol. 34. 6267â€“6274.â€¬
â€ª[36] Yifan Wang, Suyao Tang, et al. 2020. Disenhan: Disentangled heterogeneousâ€¬
â€ªgraph attention network for recommendation. In CIKM. 1605â€“1614.â€¬
â€ª[37] Zhenyi Wang, Huan Zhao, and Chuan Shi. 2022. Profiling the Design Space forâ€¬
â€ªGraph Neural Networks based Collaborative Filtering. In WSDM. 1109â€“1119.â€¬
â€ª[38] Wei Wei, Chao Huang, Lianghao Xia, Yong Xu, Jiashu Zhao, and Dawei Yin. 2022.â€¬
â€ªContrastive meta learning with behavior multiplicity for recommendation. Inâ€¬
â€ªWSDM. 1120â€“1128.â€¬
â€ª[39] Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, et al.â€¬
â€ª2021. Self-supervised graph learning for recommendation. In SIGIR. 726â€“735.â€¬
â€ª[40] Shiwen Wu, Fei Sun, Wentao Zhang, Xu Xie, et al. 2020. Graph neural networksâ€¬
â€ªin recommender systems: a survey. ACM Computing Surveys (CSUR) (2020).â€¬
â€ª[41] Lianghao Xia, Chao Huang, Chunzhen Huang, Kangyi Lin, Tao Yu, and Benâ€¬
â€ªKao. 2023. Automated Self-Supervised Learning for Recommendation. In WWW.â€¬
â€ª992â€“1002.â€¬
â€ª[42] Lianghao Xia, Chao Huang, Yong Xu, Jiashu Zhao, Dawei Yin, and Jimmy Huang.â€¬
â€ª2022. Hypergraph contrastive collaborative filtering. In SIGIR. 70â€“79.â€¬
â€ª[43] Yuhao Yang, Chao Huang, Lianghao Xia, Yuxuan Liang, Yanwei Yu, and Chen-â€¬
â€ªliang Li. 2022. Multi-behavior hypergraph-enhanced transformer for sequentialâ€¬
â€ªrecommendation. In KDD. 2263â€“2274.â€¬
â€ª[44] Yonghui Yang, Le Wu, Richang Hong, Kun Zhang, and Meng Wang. 2021. En-â€¬
â€ªhanced graph learning for collaborative filtering via mutual information maxi-â€¬
â€ªmization. In SIGIR. 71â€“80.â€¬
â€ª[45] Tiansheng Yao, Xinyang Yi, Derek Zhiyuan Cheng, et al. 2021. Self-supervisedâ€¬
â€ªLearning for Large-scale Item Recommendations. In CIKM. 4321â€“4330.â€¬
â€ª[46] Junliang Yu, Hongzhi Yin, Jundong Li, Qinyong Wang, Nguyen Quoc Viet Hung,â€¬
â€ªand Xiangliang Zhang. 2021. Self-Supervised Multi-Channel Hypergraph Convo-â€¬
â€ªlutional Network for Social Recommendation. In WWW. 413â€“424.â€¬
â€ª[47] Shengyu Zhang, Lingxiao Yang, Dong Yao, Yujie Lu, Fuli Feng, Zhou Zhao,â€¬
â€ªTat-seng Chua, and Fei Wu. 2022. Re4: Learning to Re-contrast, Re-attend, Re-â€¬
â€ªconstruct for Multi-interest Recommendation. In WWW. 2216â€“2226.â€¬
â€ª[48] Sen Zhao, Wei Wei, Ding Zou, and Xianling Mao. 2022. Multi-view intent disen-â€¬
â€ªtangle graph networks for bundle recommendation. AAAI (2022).â€¬
â€ª[49] Kun Zhou, Hui Wang, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng Zhang,â€¬
â€ªZhongyuan Wang, et al. 2020. S3-rec: Self-supervised learning for sequentialâ€¬
â€ªrecommendation with mutual information maximization. In CIKM. 1893â€“1902.â€¬
â€ª[50] Yaochen Zhu and Zhenzhong Chen. 2022. Mutually-regularized dual collaborativeâ€¬
â€ªvariational auto-encoder for recommendation systems. In WWW. 2379â€“2387.â€¬
â€ª[51] Ding Zou, Wei Wei, Ziyang Wang, Xian-Ling Mao, Feida Zhu, Rui Fang, andâ€¬
â€ªDangyang Chen. 2022. Improving knowledge-aware recommendation with multi-â€¬
â€ªlevel interactive contrastive learning. In CIKM. 2817â€“2826.â€¬